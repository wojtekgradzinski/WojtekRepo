{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "img = cv2.imread('Green_lion.jpg',1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "img = cv2.resize(img,(0,0), fx= 0.5 , fy= 0.5)\r\n",
    "cv2.imshow('image',img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#save the image\r\n",
    "cv2.imwrite('wojtek.jpg', img)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#rotate the image\r\n",
    "\r\n",
    "img_rotate = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\r\n",
    "cv2.imshow('image',img_rotate)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#slicing image\r\n",
    "cv2.imshow('image',img[100:250][50:450])\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#adding random pixels\r\n",
    "img_c = img.copy()\r\n",
    "\r\n",
    "for i in range(200):\r\n",
    "    for j in range(img.shape[0]):\r\n",
    "        img_c[i][j] = [random.randint(0,255), random.randint(0,255), random.randint(0,255)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow('image',img_c)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(img.shape)\r\n",
    "print(img.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#copy part of an image to an image\r\n",
    "img = cv2.imread('Green_lion.jpg',1)\r\n",
    "tag = img[200:400, 750:950]    #mi has to be the same rang betwwen numbers i.e between 200:400 is the smame range as 100:300 czyli 200 pixels\r\n",
    "img[100:300, 750:950] = tag\r\n",
    "\r\n",
    "cv2.imshow('Image', img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4460/2311970755.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#copy part of an image to an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Green_lion.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m750\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m950\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m#mi has to be the same rang betwwen numbers i.e between 200:400 is the smame range as 100:300 czyli 200 pixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m750\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m950\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(img.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\r\n",
    "#capture video\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  \r\n",
    "  image =np.zeros(frame.shape, np.uint8)\r\n",
    "  \r\n",
    "  smaller_frame = cv2.resize(frame,(0,0), fx=0.5, fy=0.5)\r\n",
    "  image[:height//2 , :width//2] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180)\r\n",
    "  image[height//2: , :width//2] = smaller_frame\r\n",
    "  image[:height//2 , width//2:] = smaller_frame\r\n",
    "  image[height//2: , width//2:] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180)\r\n",
    "  \r\n",
    "  \r\n",
    "  cv2.imshow('frame', image)\r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  img  = cv2.line(frame, (0,0), (width,height),(255,0,0), 10)\r\n",
    "  img  = cv2.line(img, (0,height),(width,0), (0,0,255), 18)\r\n",
    "  img = cv2.rectangle(img,(100,100), (200,200), (128,128,128), 2)\r\n",
    "  img - cv2.circle(img,(300,300), 150, (25,0,0),5) \r\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\r\n",
    "  img = cv2.putText(img, 'WOJTEK', (250, height -20),font,1, (255,255,255), 5, cv2.LINE_AA)\r\n",
    "  \r\n",
    "  cv2.imshow('frame', img)\r\n",
    "  \r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Tinsae code\r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "\r\n",
    "image = cv2.imread('Green_lion.jpg')\r\n",
    "background = cv2.imread('night1.jpg')\r\n",
    "\r\n",
    "#background = np.ones(image.shape,dtype=np.uint8)*144\r\n",
    "\r\n",
    "#changing the background size equal to the image\r\n",
    "background = cv2.resize(background, (image.shape[1],image.shape[0]), interpolation = cv2.INTER_AREA)\r\n",
    "background = cv2.cvtColor(background,cv2.COLOR_BGR2HSV)\r\n",
    "\r\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
    "\r\n",
    "lower_green = np.array([36,0,0])\r\n",
    "upper_green = np.array([86, 255,255])\r\n",
    "\r\n",
    "#mask for the background\r\n",
    "mask = cv2.inRange(hsv, lower_green, upper_green)\r\n",
    "\r\n",
    "mask_inv = cv2.bitwise_not(mask)\r\n",
    "\r\n",
    "background = cv2.bitwise_and(background,background, mask=mask)\r\n",
    "target = cv2.bitwise_and(hsv,hsv, mask=mask_inv)\r\n",
    "target = cv2.bitwise_or(target,background)\r\n",
    "print(mask.shape)\r\n",
    "BGR = cv2.cvtColor(target,cv2.COLOR_HSV2BGR)\r\n",
    "cv2.imshow('lion',BGR)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(720, 1280)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  \r\n",
    "  \r\n",
    "  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\r\n",
    "  lower_blue = np.array([90,50,50])\r\n",
    "  upper_blue = np.array([130,255,255])\r\n",
    "  \r\n",
    "  mask = cv2.inRange(hsv, lower_blue, upper_blue)\r\n",
    "  \r\n",
    "  result = cv2.bitwise_and(frame, frame, mask=mask )\r\n",
    "  \r\n",
    "  cv2.imshow('frame', result)\r\n",
    "  \r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14964/793198321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#corners detection\r\n",
    "import numpy as np\r\n",
    "import cv2 \r\n",
    "\r\n",
    "path= 'chessboard.png'\r\n",
    "\r\n",
    "img= cv2.imread(path)\r\n",
    "img= cv2.resize(img, (0,0), fx=0.5, fy=0.5)\r\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
    "\r\n",
    "\r\n",
    "corners = cv2.goodFeaturesToTrack(gray,100,0.01, 10)\r\n",
    "#converting corners to integers\r\n",
    "corners = np.int0(corners)\r\n",
    "for corner in corners:\r\n",
    "    x,y =corner.ravel() \r\n",
    "    cv2.circle(img,(x,y), 5, (255,0,0), -1)\r\n",
    "\r\n",
    "for i in range(len(corners)):\r\n",
    "    for j in range(i + 1, len(corners)):\r\n",
    "        corner1 = tuple(corners[i][0])\r\n",
    "        corner2 = tuple(corners[j][0])\r\n",
    "        #GENERATE RANDOM COLORS\r\n",
    "        color = tuple(map(lambda x: int(x), np.random.randint(0, 255, size=3)))\r\n",
    "        cv2.line(img, corner1, corner2, color, 1)\r\n",
    "\r\n",
    "cv2.imshow('img',img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(corners)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[300 300]]\n",
      "\n",
      " [[299 373]]\n",
      "\n",
      " [[226 300]]\n",
      "\n",
      " [[373 299]]\n",
      "\n",
      " [[300 226]]\n",
      "\n",
      " [[226 373]]\n",
      "\n",
      " [[373 226]]\n",
      "\n",
      " [[373 373]]\n",
      "\n",
      " [[226 226]]\n",
      "\n",
      " [[448 300]]\n",
      "\n",
      " [[151 299]]\n",
      "\n",
      " [[300 448]]\n",
      "\n",
      " [[299 151]]\n",
      "\n",
      " [[373 447]]\n",
      "\n",
      " [[447 373]]\n",
      "\n",
      " [[152 226]]\n",
      "\n",
      " [[226 152]]\n",
      "\n",
      " [[226 447]]\n",
      "\n",
      " [[152 373]]\n",
      "\n",
      " [[447 226]]\n",
      "\n",
      " [[373 152]]\n",
      "\n",
      " [[152 447]]\n",
      "\n",
      " [[447 152]]\n",
      "\n",
      " [[447 447]]\n",
      "\n",
      " [[152 152]]\n",
      "\n",
      " [[299 522]]\n",
      "\n",
      " [[ 77 300]]\n",
      "\n",
      " [[522 299]]\n",
      "\n",
      " [[300  77]]\n",
      "\n",
      " [[226 521]]\n",
      "\n",
      " [[ 78 373]]\n",
      "\n",
      " [[521 226]]\n",
      "\n",
      " [[373  78]]\n",
      "\n",
      " [[373 521]]\n",
      "\n",
      " [[521 373]]\n",
      "\n",
      " [[ 78 226]]\n",
      "\n",
      " [[226  78]]\n",
      "\n",
      " [[447 521]]\n",
      "\n",
      " [[521 447]]\n",
      "\n",
      " [[ 78 152]]\n",
      "\n",
      " [[152  78]]\n",
      "\n",
      " [[ 78 447]]\n",
      "\n",
      " [[521 152]]\n",
      "\n",
      " [[447  78]]\n",
      "\n",
      " [[152 521]]\n",
      "\n",
      " [[ 78 521]]\n",
      "\n",
      " [[521  78]]\n",
      "\n",
      " [[521 521]]\n",
      "\n",
      " [[ 78  78]]\n",
      "\n",
      " [[299 595]]\n",
      "\n",
      " [[  4 300]]\n",
      "\n",
      " [[595 299]]\n",
      "\n",
      " [[300   4]]\n",
      "\n",
      " [[  4 373]]\n",
      "\n",
      " [[595 226]]\n",
      "\n",
      " [[226 595]]\n",
      "\n",
      " [[373   4]]\n",
      "\n",
      " [[447 595]]\n",
      "\n",
      " [[152   4]]\n",
      "\n",
      " [[595 447]]\n",
      "\n",
      " [[  4 152]]\n",
      "\n",
      " [[ 78 595]]\n",
      "\n",
      " [[  4 521]]\n",
      "\n",
      " [[595  78]]\n",
      "\n",
      " [[521   4]]\n",
      "\n",
      " [[595 595]]\n",
      "\n",
      " [[  4   4]]\n",
      "\n",
      " [[374 595]]\n",
      "\n",
      " [[595 374]]\n",
      "\n",
      " [[  4 225]]\n",
      "\n",
      " [[225   4]]\n",
      "\n",
      " [[151 595]]\n",
      "\n",
      " [[595 151]]\n",
      "\n",
      " [[448   4]]\n",
      "\n",
      " [[  4 448]]\n",
      "\n",
      " [[523 595]]\n",
      "\n",
      " [[595 523]]\n",
      "\n",
      " [[  4  76]]\n",
      "\n",
      " [[ 76   4]]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#template matching\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "\r\n",
    "#reading img and template\r\n",
    "img = cv2.resize(cv2.imread('C:/Users/Wojtek/OneDrive/Desktop/STRIVE SCHOOL/WojtekRepo/6. Computer Vision/OpenCV-Tutorials-main/OpenCV-Tutorials-main/assets/soccer_practice.jpg',0),(0,0), fx= 0.8, fy= 0.8)\r\n",
    "\r\n",
    "template = cv2.resize(cv2.imread('C:/Users/Wojtek/OneDrive/Desktop/STRIVE SCHOOL/WojtekRepo/6. Computer Vision/OpenCV-Tutorials-main/OpenCV-Tutorials-main/assets/ball.PNG',0),(0,0), fx=0.8, fy=0.8)\r\n",
    "\r\n",
    "\r\n",
    "height,width = template.shape\r\n",
    "\r\n",
    "#methods available\r\n",
    "\r\n",
    "methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR,\r\n",
    "            cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]\r\n",
    "\r\n",
    "for method in methods:\r\n",
    "    img_copy = img.copy()\r\n",
    "    \r\n",
    "    result = cv2.matchTemplate(img_copy, template, method)\r\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\r\n",
    "    \r\n",
    "    #find min, max location\r\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\r\n",
    "        location = min_loc\r\n",
    "    else:\r\n",
    "        location = max_loc  \r\n",
    "    \r\n",
    "    #draw rectangle\r\n",
    "    bottom_right = (location[0]+ width, location[1] + height)  \r\n",
    "    \r\n",
    "    cv2.rectangle(img_copy, location, bottom_right,255,5)\r\n",
    "    cv2.imshow('match', img_copy)\r\n",
    "    cv2.waitKey(0)\r\n",
    "    cv2.destroyAllWindows()      "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#face and eye detection\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \r\n",
    "import cv2\r\n",
    "\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "face_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
    "eye_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\r\n",
    "\r\n",
    "while True:\r\n",
    "    ret, frame = cap.read()\r\n",
    "    \r\n",
    "    #change img to grayscale for better detection accuracy\r\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
    "    #reduce face by 30%, min Neighbours 5\r\n",
    "    faces = face_detection.detectMultiScale(gray,1.3, 5)\r\n",
    "    \r\n",
    "    \r\n",
    "    #drawing rectangles around faces\r\n",
    "    for (x,y,w,h) in faces:\r\n",
    "        cv2.rectangle(frame, (x,y), (x + w, y + h), (255,0,0) , 5)\r\n",
    "        roi_gray = gray[y:y+w, x:x+w]\r\n",
    "        roi_color = frame[y:y+h, x:x+w]\r\n",
    "        eyes = eye_detection.detectMultiScale(roi_gray, 1.3, 5)\r\n",
    "        for (ex, ey, ew, eh) in eyes:\r\n",
    "           cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh),(0,255,0) , 5) \r\n",
    "\r\n",
    "    cv2.imshow('frame',frame)\r\n",
    "    if cv2.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "    \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class Cartoonizer: \r\n",
    "    \"\"\"Cartoonizer effect \r\n",
    "        A class that applies a cartoon effect to an image. \r\n",
    "        The class uses a bilateral filter and adaptive thresholding to create \r\n",
    "        a cartoon effect. \r\n",
    "    \"\"\"\r\n",
    "    def __init__(self): \r\n",
    "        pass\r\n",
    "  \r\n",
    "    def render(self, img_rgb): \r\n",
    "        img_rgb = cv2.imread(img_rgb) \r\n",
    "        img_rgb = cv2.resize(img_rgb, (1366,768)) \r\n",
    "        numDownSamples = 2     # number of downscaling steps \r\n",
    "        numBilateralFilters = 50 # number of bilateral filtering steps \r\n",
    "  \r\n",
    "        # -- STEP 1 -- \r\n",
    "  \r\n",
    "        # downsample image using Gaussian pyramid \r\n",
    "        img_color = img_rgb \r\n",
    "        for _ in range(numDownSamples): \r\n",
    "            img_color = cv2.pyrDown(img_color) \r\n",
    "  \r\n",
    "        #cv2.imshow(\"downcolor\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        # repeatedly apply small bilateral filter instead of applying \r\n",
    "        # one large filter \r\n",
    "        for _ in range(numBilateralFilters): \r\n",
    "            img_color = cv2.bilateralFilter(img_color, 9, 9, 7) \r\n",
    "  \r\n",
    "        #cv2.imshow(\"bilateral filter\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        # upsample image to original size \r\n",
    "        for _ in range(numDownSamples): \r\n",
    "            img_color = cv2.pyrUp(img_color) \r\n",
    "        #cv2.imshow(\"upscaling\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEPS 2 and 3 -- \r\n",
    "        # convert to grayscale and apply median blur \r\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) \r\n",
    "        img_blur = cv2.medianBlur(img_gray, 3) \r\n",
    "        #cv2.imshow(\"grayscale+median blur\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEP 4 -- \r\n",
    "        # detect and enhance edges \r\n",
    "        img_edge = cv2.adaptiveThreshold(img_blur, 255, \r\n",
    "                                        cv2.ADAPTIVE_THRESH_MEAN_C, \r\n",
    "                                        cv2.THRESH_BINARY, 9, 2) \r\n",
    "        #cv2.imshow(\"edge\",img_edge) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEP 5 -- \r\n",
    "        # convert back to color so that it can be bit-ANDed with color image \r\n",
    "        (x,y,z) = img_color.shape \r\n",
    "        img_edge = cv2.resize(img_edge,(y,x)) \r\n",
    "        img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB) \r\n",
    "        cv2.imwrite(\"edge.png\",img_edge) \r\n",
    "        #cv2.imshow(\"step 5\", img_edge) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        #img_edge = cv2.resize(img_edge,(i for i in img_color.shape[:2])) \r\n",
    "        #print img_edge.shape, img_color.shape \r\n",
    "        return cv2.bitwise_and(img_color, img_edge) \r\n",
    "  \r\n",
    "tmp_canvas = Cartoonizer() \r\n",
    "  \r\n",
    "file_name = \"me.jpeg\" #File_name will come here \r\n",
    "res = tmp_canvas.render(file_name) \r\n",
    "  \r\n",
    "cv2.imwrite(\"Cartoon version.jpg\", res) \r\n",
    "cv2.imshow(\"Cartoon version\", res) \r\n",
    "cv2.waitKey(0) \r\n",
    "cv2.destroyAllWindows() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# importing libraries\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "  \r\n",
    "# reading image \r\n",
    "img = cv2.imread(\"me.jpeg\")\r\n",
    "   \r\n",
    "# Edges\r\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
    "gray = cv2.medianBlur(gray, 5)\r\n",
    "edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \r\n",
    "                                         cv2.THRESH_BINARY, 9, 9)\r\n",
    "   \r\n",
    "# Cartoonization\r\n",
    "color = cv2.bilateralFilter(img, 9, 250, 250)\r\n",
    "cartoon = cv2.bitwise_and(color, color, mask=edges)\r\n",
    "   \r\n",
    "   \r\n",
    "cv2.imshow(\"Image\", img)\r\n",
    "cv2.imshow(\"edges\", edges)\r\n",
    "cv2.imshow(\"Cartoon\", cartoon)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('opencv': conda)"
  },
  "interpreter": {
   "hash": "d2a3da4f8a14a710004e1da000f081811691ae42f2134c7c574d9230c2dcca9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}