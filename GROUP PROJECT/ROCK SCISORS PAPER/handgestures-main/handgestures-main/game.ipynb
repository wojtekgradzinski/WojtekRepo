{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "\r\n",
                "\r\n",
                "import numpy as np \r\n",
                "from PIL import Image\r\n",
                "import os\r\n",
                "import pandas as pd\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "import seaborn as sns\r\n",
                "from sklearn.tree          import DecisionTreeClassifier\r\n",
                "from sklearn.ensemble      import RandomForestClassifier\r\n",
                "from sklearn.ensemble      import ExtraTreesClassifier\r\n",
                "from sklearn.ensemble      import AdaBoostClassifier\r\n",
                "from sklearn.ensemble      import GradientBoostingClassifier\r\n",
                "from sklearn.experimental  import enable_hist_gradient_boosting \r\n",
                "# Necesary for HistGradientBoostingClassifier\r\n",
                "from sklearn.ensemble      import HistGradientBoostingClassifier\r\n",
                "from xgboost               import XGBClassifier\r\n",
                "from lightgbm              import LGBMClassifier\r\n",
                "from catboost              import CatBoostClassifier\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Rock= 0\r\n",
                "#Paper=1\r\n",
                "#Scissor=2"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "path = 'images'\r\n",
                "data2 = pd.DataFrame()\r\n",
                "data1 = pd.DataFrame ()\r\n",
                "for folder in os.listdir(path):\r\n",
                "    if folder == 'train':\r\n",
                "    \r\n",
                "        for f in os.listdir (path + '/' + folder):\r\n",
                "            class_data = np.zeros ( (len(os.listdir (path + '/' + folder + '/' + f )), 1025) )\r\n",
                "            print('Original shape')\r\n",
                "            print (class_data.shape)\r\n",
                "        \r\n",
                "            for i, img_name in enumerate (os.listdir (path + '/' + folder + '/' + f )):\r\n",
                "\r\n",
                "                img = Image.open (path + '/' + folder + '/' + f + '/' + img_name)\r\n",
                "                img_arr = np.array (img, dtype = int)\r\n",
                "                img_arr = img_arr.flatten()\r\n",
                "                \r\n",
                "                class_data [i, :1024] = img_arr\r\n",
                "                class_data [i, 1024]  = int (f)  #assigning target to the last column \r\n",
                "\r\n",
                "            class_data = pd.DataFrame (class_data)\r\n",
                "            data1 = pd.concat ([data1, class_data])\r\n",
                "            print('Size after concatination')\r\n",
                "            print(data1.shape)\r\n",
                "    else:\r\n",
                "        for f in os.listdir (path + '/' + folder):\r\n",
                "            class_data = np.zeros ( (len(os.listdir (path + '/' + folder + '/' + f )), 1025) )\r\n",
                "            print('Original shape')\r\n",
                "            print (class_data.shape)\r\n",
                "        \r\n",
                "            for i, img_name in enumerate (os.listdir (path + '/' + folder + '/' + f )):\r\n",
                "\r\n",
                "                img = Image.open (path + '/' + folder + '/' + f + '/' + img_name)\r\n",
                "                img_arr = np.array (img, dtype = int)\r\n",
                "                img_arr = img_arr.flatten()\r\n",
                "                \r\n",
                "                # class_data [i, :1024] = img_arr\r\n",
                "                # class_data [i, 1024]  = int (f)  #assigning target to the last column \r\n",
                "\r\n",
                "            class_data = pd.DataFrame (class_data)\r\n",
                "            data2 = pd.concat ([data2, class_data])\r\n",
                "            print('Size after concatination')\r\n",
                "            print(data2.shape)\r\n",
                "\r\n",
                "            \r\n",
                "data1.to_csv ('train_game.csv')\r\n",
                "data2.to_csv('test_game.csv')\r\n",
                "\r\n",
                "            \r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Original shape\n",
                        "(189, 1025)\n",
                        "Size after concatination\n",
                        "(189, 1025)\n",
                        "Original shape\n",
                        "(177, 1025)\n",
                        "Size after concatination\n",
                        "(366, 1025)\n",
                        "Original shape\n",
                        "(194, 1025)\n",
                        "Size after concatination\n",
                        "(560, 1025)\n",
                        "Original shape\n",
                        "(104, 1025)\n",
                        "Size after concatination\n",
                        "(104, 1025)\n",
                        "Original shape\n",
                        "(103, 1025)\n",
                        "Size after concatination\n",
                        "(207, 1025)\n",
                        "Original shape\n",
                        "(112, 1025)\n",
                        "Size after concatination\n",
                        "(319, 1025)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "data2.iloc[:,-1].unique()\r\n",
                "data2.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(319, 1025)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 21
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "\r\n",
                "#checking target column\r\n",
                "\r\n",
                "data1.iloc[:,-1].unique()\r\n",
                "data1.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(560, 1025)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 23
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "X = data1.iloc[:,:1024]\r\n",
                "y = data1.iloc[:,1024] "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "scalar = StandardScaler()\r\n",
                "\r\n",
                "data_norm_train = scalar.fit_transform(X)\r\n",
                "data_norm_test = scalar.fit_transform(data2)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "#sns.histplot(data=data_norm, bins=10)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "tree_classifiers = {\r\n",
                "  \"Decision Tree\": DecisionTreeClassifier(),\r\n",
                "  \"Extra Trees\":   ExtraTreesClassifier(),\r\n",
                "  \"Random Forest\": RandomForestClassifier(),\r\n",
                "  \"AdaBoost\":      AdaBoostClassifier(),\r\n",
                "  \"Skl GBM\":       GradientBoostingClassifier(),\r\n",
                "  \"Skl HistGBM\":   GradientBoostingClassifier(),\r\n",
                "  \"XGBoost\":       XGBClassifier(),\r\n",
                "  \"LightGBM\":      LGBMClassifier(),\r\n",
                "  \"CatBoost\":      CatBoostClassifier() \r\n",
                "}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "x_train, x_val, y_train, y_val = model_selection.train_test_split(x,y,test_size = 0.2,stratify = y,random_state = 42)\r\n",
                "\r\n",
                "# Your code goes here\r\n",
                "\r\n",
                "\r\n",
                "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\r\n",
                "\r\n",
                "\r\n",
                "for model_name, model in tree_classifiers.items(): # FOR EVERY PIPELINE (PREPRO + MODEL) -> TRAIN WITH TRAIN DATA (x_train)\r\n",
                "    start_time = time.time()\r\n",
                "    model.fit(x_train, y_train)\r\n",
                "    pred = model.predict(x_val)    # GET PREDICTIONS USING x_val\r\n",
                "    total_time = time.time() - start_time\r\n",
                "\r\n",
                "    results = results.append({\"Model\":    model_name,\r\n",
                "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\r\n",
                "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\r\n",
                "                              \"Time\":     total_time},\r\n",
                "                              ignore_index=True)\r\n",
                "                              \r\n",
                "                              \r\n",
                "\r\n",
                "\r\n",
                "# Your code goes here\r\n",
                "\r\n",
                "\r\n",
                "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\r\n",
                "results_ord.index += 1 \r\n",
                "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('wojtek': conda)"
        },
        "interpreter": {
            "hash": "273e4cd330c9365d0d8fc6d704b08084cf297120c969e21fb6416b510b92ba85"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}