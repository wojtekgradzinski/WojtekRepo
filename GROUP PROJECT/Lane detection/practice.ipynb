{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread('Green_lion.jpg',1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.resize(img,(0,0), fx= 0.5 , fy= 0.5)\r\n",
    "cv2.imshow('image',img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#save the image\r\n",
    "cv2.imwrite('wojtek.jpg', img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#rotate the image\r\n",
    "\r\n",
    "img_rotate = cv2.rotate(img,cv2.cv2.ROTATE_90_CLOCKWISE)\r\n",
    "cv2.imshow('image',img_rotate)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#slicing image\r\n",
    "cv2.imshow('image',img[100:250][50:450])\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#adding random pixels\r\n",
    "img_c = img.copy()\r\n",
    "\r\n",
    "for i in range(200):\r\n",
    "    for j in range(img.shape[0]):\r\n",
    "        img_c[i][j] = [random.randint(0,255), random.randint(0,255), random.randint(0,255)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow('image',img_c)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(img.shape)\r\n",
    "print(img.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#copy part of an image to an image\r\n",
    "img = cv2.imread('Green_lion.jpg',1)\r\n",
    "tag = img[200:400, 750:950]    #mi has to be the same rang betwwen numbers i.e between 200:400 is the smame range as 100:300 czyli 200 pixels\r\n",
    "img[100:300, 750:950] = tag\r\n",
    "\r\n",
    "cv2.imshow('Image', img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(img.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "#capture video\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  \r\n",
    "  image =np.zeros(frame.shape, np.uint8)\r\n",
    "  \r\n",
    "  smaller_frame = cv2.resize(frame,(0,0), fx=0.5, fy=0.5)\r\n",
    "  image[:height//2 , :width//2] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180)\r\n",
    "  image[height//2: , :width//2] = smaller_frame\r\n",
    "  image[:height//2 , width//2:] = smaller_frame\r\n",
    "  image[height//2: , width//2:] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180)\r\n",
    "  \r\n",
    "  \r\n",
    "  cv2.imshow('frame', image)\r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  img  = cv2.line(frame, (0,0), (width,height),(255,0,0), 10)\r\n",
    "  img  = cv2.line(img, (0,height),(width,0), (0,0,255), 18)\r\n",
    "  img = cv2.rectangle(img,(100,100), (200,200), (128,128,128), 2)\r\n",
    "  img - cv2.circle(img,(300,300), 150, (25,0,0),5) \r\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\r\n",
    "  img = cv2.putText(img, 'WOJTEK', (250, height -20),font,1, (255,255,255), 5, cv2.LINE_AA)\r\n",
    "  \r\n",
    "  cv2.imshow('frame', img)\r\n",
    "  \r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Tinsae code\r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "\r\n",
    "image = cv2.imread('Green_lion.jpg')\r\n",
    "background = cv2.imread('night1.jpg')\r\n",
    "\r\n",
    "#background = np.ones(image.shape,dtype=np.uint8)*144\r\n",
    "\r\n",
    "#changing the background size equal to the image\r\n",
    "background = cv2.resize(background, (image.shape[1],image.shape[0]), interpolation = cv2.INTER_AREA)\r\n",
    "background = cv2.cvtColor(background,cv2.COLOR_BGR2HSV)\r\n",
    "\r\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
    "\r\n",
    "lower_green = np.array([36,0,0])\r\n",
    "upper_green = np.array([86, 255,255])\r\n",
    "\r\n",
    "#mask for the background\r\n",
    "mask = cv2.inRange(hsv, lower_green, upper_green)\r\n",
    "\r\n",
    "mask_inv = cv2.bitwise_not(mask)\r\n",
    "\r\n",
    "background = cv2.bitwise_and(background,background, mask=mask)\r\n",
    "target = cv2.bitwise_and(hsv,hsv, mask=mask_inv)\r\n",
    "target = cv2.bitwise_or(target,background)\r\n",
    "print(mask.shape)\r\n",
    "BGR = cv2.cvtColor(target,cv2.COLOR_HSV2BGR)\r\n",
    "cv2.imshow('lion',BGR)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "while True:\r\n",
    "  ret,frame = cap.read()\r\n",
    "  \r\n",
    "  #3 is width 4 is height this code get the frame measurments\r\n",
    "  width  =int(cap.get(3))\r\n",
    "  height  =int(cap.get(4))\r\n",
    "  \r\n",
    "  \r\n",
    "  \r\n",
    "  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\r\n",
    "  lower_blue = np.array([90,50,50])\r\n",
    "  upper_blue = np.array([130,255,255])\r\n",
    "  \r\n",
    "  mask = cv2.inRange(hsv, lower_blue, upper_blue)\r\n",
    "  \r\n",
    "  result = cv2.bitwise_and(frame, frame, mask=mask )\r\n",
    "  \r\n",
    "  cv2.imshow('frame', result)\r\n",
    "  \r\n",
    "  if cv2.waitKey(1) == ord('q'):\r\n",
    "      break\r\n",
    "  \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#corners detection\r\n",
    "import numpy as np\r\n",
    "import cv2 \r\n",
    "\r\n",
    "path= 'chessboard.png'\r\n",
    "\r\n",
    "img= cv2.imread(path)\r\n",
    "img= cv2.resize(img, (0,0), fx=0.5, fy=0.5)\r\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
    "\r\n",
    "\r\n",
    "corners = cv2.goodFeaturesToTrack(gray,100,0.01, 10)\r\n",
    "#converting corners to integers\r\n",
    "corners = np.int0(corners)\r\n",
    "for corner in corners:\r\n",
    "    x,y =corner.ravel() \r\n",
    "    cv2.circle(img,(x,y), 5, (255,0,0), -1)\r\n",
    "\r\n",
    "for i in range(len(corners)):\r\n",
    "    for j in range(i + 1, len(corners)):\r\n",
    "        corner1 = tuple(corners[i][0])\r\n",
    "        corner2 = tuple(corners[j][0])\r\n",
    "        #GENERATE RANDOM COLORS\r\n",
    "        color = tuple(map(lambda x: int(x), np.random.randint(0, 255, size=3)))\r\n",
    "        cv2.line(img, corner1, corner2, color, 1)\r\n",
    "\r\n",
    "cv2.imshow('img',img)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18272/3282752386.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(corners)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#template matching\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "\r\n",
    "#reading img and template\r\n",
    "img = cv2.resize(cv2.imread('C:/Users/Wojtek/OneDrive/Desktop/STRIVE SCHOOL/WojtekRepo/6. Computer Vision/OpenCV-Tutorials-main/OpenCV-Tutorials-main/assets/soccer_practice.jpg',0),(0,0), fx= 0.8, fy= 0.8)\r\n",
    "\r\n",
    "template = cv2.resize(cv2.imread('C:/Users/Wojtek/OneDrive/Desktop/STRIVE SCHOOL/WojtekRepo/6. Computer Vision/OpenCV-Tutorials-main/OpenCV-Tutorials-main/assets/ball.PNG',0),(0,0), fx=0.8, fy=0.8)\r\n",
    "\r\n",
    "\r\n",
    "height,width = template.shape\r\n",
    "\r\n",
    "#methods available\r\n",
    "\r\n",
    "methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR,\r\n",
    "            cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]\r\n",
    "\r\n",
    "for method in methods:\r\n",
    "    img_copy = img.copy()\r\n",
    "    \r\n",
    "    result = cv2.matchTemplate(img_copy, template, method)\r\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\r\n",
    "    \r\n",
    "    #find min, max location\r\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\r\n",
    "        location = min_loc\r\n",
    "    else:\r\n",
    "        location = max_loc  \r\n",
    "    \r\n",
    "    #draw rectangle\r\n",
    "    bottom_right = (location[0]+ width, location[1] + height)  \r\n",
    "    \r\n",
    "    cv2.rectangle(img_copy, location, bottom_right,255,5)\r\n",
    "    cv2.imshow('match', img_copy)\r\n",
    "    cv2.waitKey(0)\r\n",
    "    cv2.destroyAllWindows()      "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#face and eye detection\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \r\n",
    "import cv2\r\n",
    "\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "face_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
    "eye_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\r\n",
    "\r\n",
    "while True:\r\n",
    "    ret, frame = cap.read()\r\n",
    "    \r\n",
    "    #change img to grayscale for better detection accuracy\r\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
    "    #reduce face by 30%, min Neighbours 5\r\n",
    "    faces = face_detection.detectMultiScale(gray,1.3, 5)\r\n",
    "    \r\n",
    "    \r\n",
    "    #drawing rectangles around faces\r\n",
    "    for (x,y,w,h) in faces:\r\n",
    "        cv2.rectangle(frame, (x,y), (x + w, y + h), (255,0,0) , 5)\r\n",
    "        roi_gray = gray[y:y+w, x:x+w]\r\n",
    "        roi_color = frame[y:y+h, x:x+w]\r\n",
    "        eyes = eye_detection.detectMultiScale(roi_gray, 1.3, 5)\r\n",
    "        for (ex, ey, ew, eh) in eyes:\r\n",
    "           cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh),(0,255,0) , 5) \r\n",
    "\r\n",
    "    cv2.imshow('frame',frame)\r\n",
    "    if cv2.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "    \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Cartoonizer: \r\n",
    "    \"\"\"Cartoonizer effect \r\n",
    "        A class that applies a cartoon effect to an image. \r\n",
    "        The class uses a bilateral filter and adaptive thresholding to create \r\n",
    "        a cartoon effect. \r\n",
    "    \"\"\"\r\n",
    "    def __init__(self): \r\n",
    "        pass\r\n",
    "  \r\n",
    "    def render(self, img_rgb): \r\n",
    "        img_rgb = cv2.imread(img_rgb) \r\n",
    "        img_rgb = cv2.resize(img_rgb, (1366,768)) \r\n",
    "        numDownSamples = 2     # number of downscaling steps \r\n",
    "        numBilateralFilters = 50 # number of bilateral filtering steps \r\n",
    "  \r\n",
    "        # -- STEP 1 -- \r\n",
    "  \r\n",
    "        # downsample image using Gaussian pyramid \r\n",
    "        img_color = img_rgb \r\n",
    "        for _ in range(numDownSamples): \r\n",
    "            img_color = cv2.pyrDown(img_color) \r\n",
    "  \r\n",
    "        #cv2.imshow(\"downcolor\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        # repeatedly apply small bilateral filter instead of applying \r\n",
    "        # one large filter \r\n",
    "        for _ in range(numBilateralFilters): \r\n",
    "            img_color = cv2.bilateralFilter(img_color, 9, 9, 7) \r\n",
    "  \r\n",
    "        #cv2.imshow(\"bilateral filter\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        # upsample image to original size \r\n",
    "        for _ in range(numDownSamples): \r\n",
    "            img_color = cv2.pyrUp(img_color) \r\n",
    "        #cv2.imshow(\"upscaling\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEPS 2 and 3 -- \r\n",
    "        # convert to grayscale and apply median blur \r\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) \r\n",
    "        img_blur = cv2.medianBlur(img_gray, 3) \r\n",
    "        #cv2.imshow(\"grayscale+median blur\",img_color) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEP 4 -- \r\n",
    "        # detect and enhance edges \r\n",
    "        img_edge = cv2.adaptiveThreshold(img_blur, 255, \r\n",
    "                                        cv2.ADAPTIVE_THRESH_MEAN_C, \r\n",
    "                                        cv2.THRESH_BINARY, 9, 2) \r\n",
    "        #cv2.imshow(\"edge\",img_edge) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "  \r\n",
    "        # -- STEP 5 -- \r\n",
    "        # convert back to color so that it can be bit-ANDed with color image \r\n",
    "        (x,y,z) = img_color.shape \r\n",
    "        img_edge = cv2.resize(img_edge,(y,x)) \r\n",
    "        img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB) \r\n",
    "        cv2.imwrite(\"edge.png\",img_edge) \r\n",
    "        #cv2.imshow(\"step 5\", img_edge) \r\n",
    "        #cv2.waitKey(0) \r\n",
    "        #img_edge = cv2.resize(img_edge,(i for i in img_color.shape[:2])) \r\n",
    "        #print img_edge.shape, img_color.shape \r\n",
    "        return cv2.bitwise_and(img_color, img_edge) \r\n",
    "  \r\n",
    "tmp_canvas = Cartoonizer() \r\n",
    "  \r\n",
    "file_name = \"me.jpeg\" #File_name will come here \r\n",
    "res = tmp_canvas.render(file_name) \r\n",
    "  \r\n",
    "cv2.imwrite(\"Cartoon version.jpg\", res) \r\n",
    "cv2.imshow(\"Cartoon version\", res) \r\n",
    "cv2.waitKey(0) \r\n",
    "cv2.destroyAllWindows() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# importing libraries\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "  \r\n",
    "# reading image \r\n",
    "img = cv2.imread(\"me.jpeg\")\r\n",
    "   \r\n",
    "# Edges\r\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
    "gray = cv2.medianBlur(gray, 5)\r\n",
    "edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \r\n",
    "                                         cv2.THRESH_BINARY, 9, 9)\r\n",
    "   \r\n",
    "# Cartoonization\r\n",
    "color = cv2.bilateralFilter(img, 9, 250, 250)\r\n",
    "cartoon = cv2.bitwise_and(color, color, mask=edges)\r\n",
    "   \r\n",
    "   \r\n",
    "cv2.imshow(\"Image\", img)\r\n",
    "cv2.imshow(\"edges\", edges)\r\n",
    "cv2.imshow(\"Cartoon\", cartoon)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2 \r\n",
    "import numpy as np \r\n",
    "\r\n",
    "\r\n",
    "def canny(img):\r\n",
    "    \r\n",
    "    #convert to grayscale for better accuracy    \r\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \r\n",
    "    #set the kernel size for blur transformation to reduce noise\r\n",
    "    kernel = 5\r\n",
    "    blur = cv2.GaussianBlur(gray, (kernel, kernel), 0)\r\n",
    "    #defining edges with canny\r\n",
    "    canny = cv2.Canny(gray, 50,150)\r\n",
    "    return canny    \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "cap = cv2.VideoCapture('test1.mp4')\r\n",
    "while True:\r\n",
    "    ret, frame = cap.read()\r\n",
    "    #detecting edges\r\n",
    "    canny_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   \r\n",
    "    cv2.imshow('canny_image', canny_image)\r\n",
    "    \r\n",
    "    \r\n",
    "    if cv2.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "    \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def canny(img):\r\n",
    "    \r\n",
    "    #convert to grayscale for better accuracy    \r\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \r\n",
    "    #set the kernel size for blur transformation to reduce noise\r\n",
    "    kernel = 5\r\n",
    "    blur = cv2.GaussianBlur(gray, (kernel, kernel), 0)\r\n",
    "    #defining edges with canny\r\n",
    "    canny = cv2.Canny(gray, 50,150)\r\n",
    "    return canny \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    " \r\n",
    "def canny(img):\r\n",
    "    if img is None:\r\n",
    "        cap.release()\r\n",
    "        cv2.destroyAllWindows()\r\n",
    "        exit()\r\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
    "    kernel = 5\r\n",
    "    blur = cv2.GaussianBlur(gray,(kernel, kernel),0)\r\n",
    "    canny = cv2.Canny(gray, 50, 150)\r\n",
    "    return canny\r\n",
    "\r\n",
    "def region_of_interest(canny):\r\n",
    "    height = canny.shape[0]\r\n",
    "    width = canny.shape[1]\r\n",
    "    mask = np.zeros_like(canny)\r\n",
    "    triangle = np.array([[\r\n",
    "    (200, height),\r\n",
    "    (800, 350),\r\n",
    "    (1200, height),]], np.int32)\r\n",
    "    cv2.fillPoly(mask, triangle, 255)\r\n",
    "    masked_image = cv2.bitwise_and(canny, mask)\r\n",
    "    return masked_image\r\n",
    "\r\n",
    "def houghLines(cropped_canny):\r\n",
    "    return cv2.HoughLinesP(cropped_canny, 2, np.pi/180, 100, \r\n",
    "        np.array([]), minLineLength=40, maxLineGap=5)\r\n",
    "\r\n",
    "def addWeighted(frame, line_image):\r\n",
    "    return cv2.addWeighted(frame, 0.8, line_image, 1, 1)\r\n",
    " \r\n",
    "def display_lines(img,lines):\r\n",
    "    line_image = np.zeros_like(img)\r\n",
    "    if lines is not None:\r\n",
    "        for line in lines:\r\n",
    "            for x1, y1, x2, y2 in line:\r\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),10)\r\n",
    "    return line_image\r\n",
    " \r\n",
    "def make_points(image, line):\r\n",
    "    slope, intercept = line\r\n",
    "    y1 = int(image.shape[0])\r\n",
    "    y2 = int(y1*3.0/5)      \r\n",
    "    x1 = int((y1 - intercept)/slope)\r\n",
    "    x2 = int((y2 - intercept)/slope)\r\n",
    "    return [[x1, y1, x2, y2]]\r\n",
    " \r\n",
    "def average_slope_intercept(image, lines):\r\n",
    "    left_fit    = []\r\n",
    "    right_fit   = []\r\n",
    "    if lines is None:\r\n",
    "        return None\r\n",
    "    for line in lines:\r\n",
    "        for x1, y1, x2, y2 in line:\r\n",
    "            fit = np.polyfit((x1,x2), (y1,y2), 1)\r\n",
    "            slope = fit[0]\r\n",
    "            intercept = fit[1]\r\n",
    "            if slope < 0: \r\n",
    "                left_fit.append((slope, intercept))\r\n",
    "            else:\r\n",
    "                right_fit.append((slope, intercept))\r\n",
    "    left_fit_average  = np.average(left_fit, axis=0)\r\n",
    "    right_fit_average = np.average(right_fit, axis=0)\r\n",
    "    left_line  = make_points(image, left_fit_average)\r\n",
    "    right_line = make_points(image, right_fit_average)\r\n",
    "    averaged_lines = [left_line, right_line]\r\n",
    "    return averaged_lines\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(\"test1.mp4\")\r\n",
    "while True:\r\n",
    "    _, frame = cap.read()\r\n",
    "    canny_image = canny(frame)\r\n",
    "    cropped_canny = region_of_interest(canny_image)\r\n",
    "    # cv2.imshow(\"cropped_canny\",cropped_canny)\r\n",
    "\r\n",
    "    lines = houghLines(cropped_canny)\r\n",
    "    averaged_lines = average_slope_intercept(frame, lines)\r\n",
    "    line_image = display_lines(frame, averaged_lines)\r\n",
    "    combo_image = addWeighted(frame, line_image)\r\n",
    "    cv2.imshow(\"result\", combo_image)\r\n",
    "    \r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def region_of_interest(canny):\r\n",
    "    \r\n",
    "    height = canny.shape[0]\r\n",
    "    width =canny.shape[1]\r\n",
    "    mask = np.zeros(canny)\r\n",
    "    triangle = np.array([[(200, height),\r\n",
    "                          (800, 350),\r\n",
    "                          (1200, height), ]], np.int32)\r\n",
    "    cv2.fillPoly(mask, triangle, 255)\r\n",
    "    masked_image = cv2.bitwise_and(canny, mask)\r\n",
    "    return masked_image\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('cv': conda)"
  },
  "interpreter": {
   "hash": "1c5fa964adacad1a748d85cbae08cf2374ebb924ae513411bb4d5c6ebb03aa36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}