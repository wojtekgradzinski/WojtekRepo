{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST Classifier\n",
    "\n",
    "In this notebook you will create both, an mnist tabular dataset and a classifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.- import the Operating System (os) module in python and any other library you need"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import PIL.Image\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.- As you can see each class has its own folder (Do it only for train). \n",
    "\n",
    "    - Iterate folder by folder ( os.listdir() )\n",
    "    - Inside each folder: \n",
    "        1.- Read the image\n",
    "        2.- Reshape it into a flat array (784,)\n",
    "        3.- Save the data into a pandas dataframe apending the column name as the class\n",
    "    - Save the data into a CSV\n",
    "\n",
    "    Note: if it takes to long try doing only 100 images per folder and the teacher for the CSV."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = 'DATA'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.- Load the CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "for folder in os.listdir('data'):\r\n",
    "    # print (folder)\r\n",
    "    if folder == 'trainingSet':\r\n",
    "        for folder_inside in os.listdir (data +'/' + folder):\r\n",
    "            print (folder_inside)     \r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dce90b6b1154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# print (folder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'trainingSet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfolder_inside\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfolder_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "data1 = pd.DataFrame ()\r\n",
    "\r\n",
    "for folder in os.listdir('data'):\r\n",
    "    if folder == 'trainingSet':\r\n",
    "    \r\n",
    "        for f in os.listdir (data + '/' + folder):\r\n",
    "            class_data = np.zeros ( (len(os.listdir (data + '/' + folder + '/' + f )), 785) )\r\n",
    "            print (class_data.shape)\r\n",
    "        \r\n",
    "            for i, img_name in enumerate (os.listdir (data + '/' + folder + '/' + f )):\r\n",
    "\r\n",
    "                img = PIL.Image.open (data + '/' + folder + '/' + f + '/' + img_name)\r\n",
    "                img_arr = np.array (img, dtype = int)\r\n",
    "                img_arr = img_arr.flatten()\r\n",
    "                \r\n",
    "                class_data [i, :784] = img_arr\r\n",
    "                class_data [i, 784]  = int (f)\r\n",
    "\r\n",
    "            class_data = pd.DataFrame (class_data)\r\n",
    "            data1 = pd.concat ([data1, class_data])\r\n",
    "            print(data1.shape)\r\n",
    "\r\n",
    "            \r\n",
    "data1.to_csv ('mnist.csv')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4132, 785)\n",
      "(4684, 785)\n",
      "(4177, 785)\n",
      "(4351, 785)\n",
      "(4072, 785)\n",
      "(3795, 785)\n",
      "(4137, 785)\n",
      "(4401, 785)\n",
      "(4063, 785)\n",
      "(4188, 785)\n",
      "(4188, 785)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "parent_dir = \"Data\"\r\n",
    "data = pd.DataFrame()\r\n",
    "for folder in os.listdir(parent_dir):\r\n",
    "\r\n",
    "    print(folder)\r\n",
    "\r\n",
    "    if folder == \"trainingSet\":\r\n",
    "        for f in os.listdir(parent_dir+\"/\"+folder):\r\n",
    "\r\n",
    "            class_data = np.zeros(  ( len(os.listdir(parent_dir+\"/\"+folder+\"/\"+f) ), 785) )\r\n",
    "            print(class_data.shape)\r\n",
    "\r\n",
    "            for i, img_name in enumerate(os.listdir(parent_dir+\"/\"+folder+\"/\"+f)):\r\n",
    "\r\n",
    "                img = PIL.Image.open(parent_dir+\"/\"+folder+\"/\"+f+\"/\"+img_name)\r\n",
    "                img_arr = np.array(img, dtype=int)\r\n",
    "                img_arr = img_arr.flatten()\r\n",
    "                class_data[i,:784] = img_arr\r\n",
    "                class_data[i,784] = int(f)\r\n",
    "\r\n",
    "            class_data = pd.DataFrame(class_data)\r\n",
    "            data = pd.concat([data, class_data])\r\n",
    "            print(data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "testSample\n",
      "testSet\n",
      "trainingSample\n",
      "trainingSet\n",
      "(4132, 785)\n",
      "(4132, 785)\n",
      "(4684, 785)\n",
      "(8816, 785)\n",
      "(4177, 785)\n",
      "(12993, 785)\n",
      "(4351, 785)\n",
      "(17344, 785)\n",
      "(4072, 785)\n",
      "(21416, 785)\n",
      "(3795, 785)\n",
      "(25211, 785)\n",
      "(4137, 785)\n",
      "(29348, 785)\n",
      "(4401, 785)\n",
      "(33749, 785)\n",
      "(4063, 785)\n",
      "(37812, 785)\n",
      "(4188, 785)\n",
      "(42000, 785)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.- Create a dictionary of models (No preprocessing needed, it has already been done).\n",
    "    \n",
    "    Include both, tree models and mult models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "import numpy    as np\r\n",
    "from numpy.testing._private.utils import decorate_methods\r\n",
    "import pandas   as pd\r\n",
    "import seaborn  as sb\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sklearn  as skl\r\n",
    "import time\r\n",
    "\r\n",
    "from sklearn import pipeline      # Pipeline\r\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\r\n",
    "from sklearn import impute\r\n",
    "from sklearn import compose\r\n",
    "from sklearn import model_selection # train_test_split\r\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\r\n",
    "from sklearn import set_config\r\n",
    "\r\n",
    "from sklearn.tree          import DecisionTreeRegressor\r\n",
    "from sklearn.ensemble      import RandomForestRegressor\r\n",
    "from sklearn.ensemble      import ExtraTreesRegressor\r\n",
    "from sklearn.ensemble      import AdaBoostRegressor\r\n",
    "from sklearn.ensemble      import GradientBoostingRegressor\r\n",
    "from xgboost               import XGBRegressor\r\n",
    "from lightgbm              import LGBMRegressor\r\n",
    "from catboost              import CatBoostRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tree_classifiers = {\r\n",
    "  \"Decision Tree\": DecisionTreeRegressor(),\r\n",
    "  \"Extra Trees\":   ExtraTreesRegressor(n_estimators=100),\r\n",
    "  \"Random Forest\": RandomForestRegressor(n_estimators=100),\r\n",
    "  \"AdaBoost\":      AdaBoostRegressor(n_estimators=100),\r\n",
    "  \"Skl GBM\":       GradientBoostingRegressor(n_estimators=100),\r\n",
    "  \"XGBoost\":       XGBRegressor(n_estimators=100),\r\n",
    "  \"LightGBM\":      LGBMRegressor(n_estimators=100),\r\n",
    "  \"CatBoost\":      CatBoostRegressor(n_estimators=100),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.- Using either cross validation or stratification find out which is the best model\n",
    "    - Base your code on the previous two days examples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "df = pd.read_csv ('mnist.csv', index_col=0)\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8376, 785)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train, x_test, y_train, y_test = model_seection.train_test_split (x , )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional: Can you rotate an image?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "273e4cd330c9365d0d8fc6d704b08084cf297120c969e21fb6416b510b92ba85"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('wojtek': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}