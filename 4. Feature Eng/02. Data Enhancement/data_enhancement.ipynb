{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('dl': conda)"
  },
  "interpreter": {
   "hash": "6afb89b99e84bee04d6330a29f1bb71213540d48d5fe88c31e05e7f9706c13f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.style.use(style='seaborn')\r\n",
    "%matplotlib inline\r\n",
    "import time\r\n",
    "\r\n",
    "from IPython.display import clear_output\r\n",
    "import numpy    as np\r\n",
    "import pandas   as pd\r\n",
    "import seaborn  as sb\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sklearn  as skl\r\n",
    "\r\n",
    "from sklearn import pipeline      # Pipeline\r\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\r\n",
    "from sklearn import impute\r\n",
    "from sklearn import compose\r\n",
    "from sklearn import model_selection # train_test_split\r\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\r\n",
    "from sklearn import set_config\r\n",
    "\r\n",
    "from sklearn.tree          import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble      import RandomForestClassifier\r\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\r\n",
    "from sklearn.ensemble      import AdaBoostClassifier\r\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\r\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\r\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\r\n",
    "from xgboost               import XGBClassifier\r\n",
    "from lightgbm              import LGBMClassifier\r\n",
    "from catboost              import CatBoostClassifier\r\n",
    "\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "from sklearn import linear_model #for lasso\r\n",
    "from sklearn.model_selection import cross_val_predict\r\n",
    "from sklearn import model_selection \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('./Data/london_merged.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cnt    t1    t2   hum  wind_speed  weather_code  is_holiday  \\\n",
       "6171    343  13.0  13.0  88.0         6.5           2.0         0.0   \n",
       "11752   597  16.0  16.0  94.0        21.0           7.0         0.0   \n",
       "3672   2066  17.0  17.0  42.0        24.0           2.0         0.0   \n",
       "9693    137   4.0   2.0  90.0         8.0           7.0         0.0   \n",
       "7869   1029  13.5  13.5  65.0        43.0           3.0         0.0   \n",
       "\n",
       "       is_weekend  season  year month hour  \n",
       "6171          1.0     2.0  2015    09   02  \n",
       "11752         0.0     0.0  2016    05   13  \n",
       "3672          1.0     1.0  2015    06   11  \n",
       "9693          1.0     3.0  2016    02   01  \n",
       "7869          1.0     2.0  2015    11   13  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>hum</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>343</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>09</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>597</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>05</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>2066</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>06</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>137</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>1029</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "new_df = df.copy()\r\n",
    "#adding 25% features to wind speed\r\n",
    "#new_df['wind_speed'] = new_df.apply(lambda row: row['wind_speed'] + np.random.random_sample()*1000, axis=1 )\r\n",
    "#adding 25% features to temp \r\n",
    "#new_df['t2']  = new_df.apply(lambda row: row['t2'] + np.random.random_sample()*2, axis=1)\r\n",
    "\r\n",
    "df = df.append(new_df.sample(int(new_df.shape[0]/4)))\r\n",
    "\r\n",
    "#enhancing data\r\n",
    "df['year'] = df['timestamp'].apply(lambda row: row[:4])\r\n",
    "df['month'] = df['timestamp'].apply(lambda row: row[5:7])\r\n",
    "df['hour'] = df['timestamp'].apply(lambda row: row[11:13])\r\n",
    "\r\n",
    "df = df.drop(['timestamp'], axis =1)\r\n",
    "df.sample(10)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9aeaaf93fc99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#enhancing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df['season'].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3., 0., 1., 2.])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#generating data\r\n",
    "def data_enhancement(data):\r\n",
    "    \r\n",
    "    gen_data = df.copy()\r\n",
    "    for season in data['season'].unique():\r\n",
    "        seasonal_data = gen_data[ gen_data['season'] == season]\r\n",
    "        \r\n",
    "        t1_std   = seasonal_data['t1'].std()\r\n",
    "        t2_std   = seasonal_data['t2'].std()\r\n",
    "        hum_std  = seasonal_data['hum'].std()\r\n",
    "        wind_std = seasonal_data['wind_speed'].std()\r\n",
    "\r\n",
    "        for i in range(seasonal_data.shape[0]):\r\n",
    "            if np.random.randint(2) == 1: #losuje liczbe od 0 do 1  \r\n",
    "                seasonal_data['t1'].values[i] += t1_std\r\n",
    "            else:\r\n",
    "                seasonal_data['t1'].values[i] -= t1_std   \r\n",
    "\r\n",
    "            if np.random.randint(2) == 1:  \r\n",
    "                seasonal_data['t2'].values[i] += t2_std\r\n",
    "            else:\r\n",
    "                seasonal_data['t2'].values[i] -= t2_std   \r\n",
    "        \r\n",
    "            if np.random.randint(2) == 1:   \r\n",
    "                seasonal_data['hum'].values[i] += hum_std\r\n",
    "            else:\r\n",
    "                seasonal_data['hum'].values[i] -= hum_std\r\n",
    "\r\n",
    "            if np.random.randint(2) == 1:  \r\n",
    "                seasonal_data['wind_speed'].values[i] += wind_std\r\n",
    "            else:\r\n",
    "                seasonal_data['wind_speed'].values[i] -= wind_std\r\n",
    "        \r\n",
    "    return gen_data\r\n",
    "\r\n",
    "gen = data_enhancement(df)                         \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "t1_std"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 't1_std' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ec401003b68a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt1_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't1_std' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "gen"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cnt    t1         t2    hum  wind_speed  weather_code  is_holiday  \\\n",
       "0       182   3.0   2.000000   93.0    6.000000           3.0         0.0   \n",
       "1       138   3.0   2.500000   93.0    5.000000           1.0         0.0   \n",
       "2       134   2.5   2.500000   96.5    0.000000           1.0         0.0   \n",
       "3        72   2.0   2.000000  100.0    0.000000           1.0         0.0   \n",
       "4        47   2.0   0.000000   93.0    6.500000           1.0         0.0   \n",
       "...     ...   ...        ...    ...         ...           ...         ...   \n",
       "238     340   5.0   1.135830   70.0  952.981578           1.0         0.0   \n",
       "936      63   4.0   4.318563   75.0  306.405440           4.0         0.0   \n",
       "17186  3665  14.0  14.987899   77.0  125.733813           3.0         0.0   \n",
       "6020   1539  17.5  17.594161   57.5  147.351105           2.0         0.0   \n",
       "4878    521  17.5  18.639612   80.5  265.506764           2.0         0.0   \n",
       "\n",
       "       is_weekend  season  year month hour  \n",
       "0             1.0     3.0  2015    01   00  \n",
       "1             1.0     3.0  2015    01   01  \n",
       "2             1.0     3.0  2015    01   02  \n",
       "3             1.0     3.0  2015    01   03  \n",
       "4             1.0     3.0  2015    01   04  \n",
       "...           ...     ...   ...   ...  ...  \n",
       "238           0.0     3.0  2015    01   23  \n",
       "936           0.0     3.0  2015    02   02  \n",
       "17186         1.0     3.0  2016    12   12  \n",
       "6020          1.0     2.0  2015    09   19  \n",
       "4878          1.0     1.0  2015    07   21  \n",
       "\n",
       "[21767 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>hum</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>96.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>340</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.135830</td>\n",
       "      <td>70.0</td>\n",
       "      <td>952.981578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>63</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.318563</td>\n",
       "      <td>75.0</td>\n",
       "      <td>306.405440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17186</th>\n",
       "      <td>3665</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.987899</td>\n",
       "      <td>77.0</td>\n",
       "      <td>125.733813</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>1539</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.594161</td>\n",
       "      <td>57.5</td>\n",
       "      <td>147.351105</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>09</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>521</td>\n",
       "      <td>17.5</td>\n",
       "      <td>18.639612</td>\n",
       "      <td>80.5</td>\n",
       "      <td>265.506764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21767 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "cat_vars = ['weather_code', 'is_holiday','is_weekend','season','year','month']\r\n",
    "num_vars = ['t1','t2','hum','wind_speed']\r\n",
    "num_vars"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t1', 't2', 'hum', 'wind_speed']"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "y = df['cnt']\r\n",
    "x = df.drop(['cnt'], axis=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "x_train, x_val , y_train, y_val = model_selection.train_test_split(x,y ,test_size = 0.2 , random_state = 0)\r\n",
    "\r\n",
    "#generating extar samples \r\n",
    "\r\n",
    "extra_sample = gen.sample(gen.shape[0] // 3 ) # generating 30% new data\r\n",
    "\r\n",
    "#concatinating extra sample to training data\r\n",
    "x_train = pd.concat([x_train, extra_sample.drop(['cnt'], axis=1)])\r\n",
    "y_train = pd.concat([y_train, extra_sample['cnt']])\r\n",
    "\r\n",
    "#normalazing data labels\r\n",
    "transformer = preprocessing.PowerTransformer()\r\n",
    "y_train = transformer.fit_transform(y_train.values.reshape(-1,1))\r\n",
    "y_val = transformer.transform(y_val.values.reshape(-1,1))\r\n",
    "\r\n",
    "rang = abs(y_train.max()) + abs(y_train.min())\r\n",
    "\r\n",
    "#applying imputer to fill missing num & cat data\r\n",
    "\r\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[\r\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value=-9999)),\r\n",
    "])\r\n",
    "\r\n",
    "\r\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\r\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\r\n",
    "    ('ordinal', preprocessing.OrdinalEncoder())\r\n",
    "])\r\n",
    "\r\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\r\n",
    "    ('num', num_4_treeModels, num_vars),\r\n",
    "    ('cat', cat_4_treeModels, cat_vars),\r\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\r\n",
    "\r\n",
    "\r\n",
    "#dictionary of all algorithms that I am going to test \r\n",
    "tree_classifiers = {\r\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\r\n",
    "  \"Extra Trees\":ExtraTreesClassifier(),\r\n",
    "  \"Random Forest\":RandomForestClassifier(),\r\n",
    "  \"AdaBoost\":AdaBoostClassifier(),\r\n",
    "  \"Skl GBM\":GradientBoostingClassifier(),\r\n",
    "  \"Skl HistGBM\":GradientBoostingClassifier(),\r\n",
    "  \"XGBoost\":XGBClassifier(),\r\n",
    "  \"LightGBM\":LGBMClassifier(),\r\n",
    "  \"CatBoost\":CatBoostClassifier()\r\n",
    "}\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "#putting everything together\r\n",
    "\r\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepo, model) for name, model in tree_classifiers.items()}\r\n",
    "\r\n",
    "results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], \" % error\": [], 'Time': []})\r\n",
    "\r\n",
    "for model_name, model in tree_classifiers.items():\r\n",
    "    \r\n",
    "    start_time = time.time()\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "    total_time = time.time() - start_time\r\n",
    "        \r\n",
    "    pred = model.predict(x_val)\r\n",
    "    \r\n",
    "    results = results.append({\"Model\":    model_name,\r\n",
    "                              \"MSE\": metrics.mean_squared_error(y_val, pred),\r\n",
    "                              \"MAB\": metrics.mean_absolute_error(y_val, pred),\r\n",
    "                              \" % error\": metrics.mean_squared_error(y_val, pred) / rang,\r\n",
    "                              \"Time\":     total_time},\r\n",
    "                              ignore_index=True)\r\n",
    "### END SOLUTION\r\n",
    "\r\n",
    "\r\n",
    "results_ord = results.sort_values(by=['MSE'], ascending=True, ignore_index=True)\r\n",
    "results_ord.index += 1 \r\n",
    "results_ord.style.bar(subset=['MSE', 'MAE'], vmin=0, vmax=100, color='#5fba7d')\r\n",
    "\r\n",
    "print(results_ord)\r\n",
    "\r\n",
    "\r\n",
    "print(y_train.max())\r\n",
    "print(y_train.min())\r\n",
    "print(y_val[3])\r\n",
    "print(tree_classifiers['Random Forest'].predict(x_val)[3])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-f22a2bc769e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \"\"\"\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "\"\"\" ALL IN ONE CELL\"\"\"\n",
    "\n",
    "import numpy    as np\n",
    "from numpy.testing._private.utils import decorate_methods\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "import time\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.tree          import DecisionTreeRegressor\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.ensemble      import ExtraTreesRegressor\n",
    "from sklearn.ensemble      import AdaBoostRegressor\n",
    "from sklearn.ensemble      import GradientBoostingRegressor\n",
    "from xgboost               import XGBRegressor\n",
    "from lightgbm              import LGBMRegressor\n",
    "from catboost              import CatBoostRegressor\n",
    "\n",
    "data = pd.read_csv(r'Data/london_merged.csv')\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#target = data['cnt']\n",
    "#data = data.drop(['cnt'], axis=1)\n",
    "\n",
    "#Print data shape\n",
    "#print(target.shape)\n",
    "#print(data.shape)\n",
    "\n",
    "#Take a look at nulls 0 nulls\n",
    "#print(target.isnull().sum())\n",
    "#print(data.isnull().sum())\n",
    "\n",
    "#lets create a 2 new feautures\n",
    "# Hour time stamp contains the year and the month,\n",
    "# we will create different columns for each one\n",
    "\n",
    "data['year'] = data['timestamp'].apply(lambda row: row[:4])\n",
    "data['month'] = data['timestamp'].apply(lambda row: row.split('-')[2][:2] )\n",
    "data['hour'] = data['timestamp'].apply(lambda row: row.split(':')[0][-2:] )\n",
    "'''\n",
    "print(data['year'])\n",
    "print(data['month'])\n",
    "print(data['hour'])\n",
    "'''\n",
    "data.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "#print(data.shape)\n",
    "\n",
    "\n",
    "def data_enhancement(data):\n",
    "    \n",
    "    gen_data = data.copy()\n",
    "    \n",
    "    for season in data['season'].unique():\n",
    "        seasonal_data =  gen_data[gen_data['season'] == season]\n",
    "        hum_std = seasonal_data['hum'].std()\n",
    "        wind_speed_std = seasonal_data['wind_speed'].std()\n",
    "        t1_std = seasonal_data['t1'].std()\n",
    "        t2_std = seasonal_data['t2'].std()\n",
    "        \n",
    "        for i, d in enumerate(data[data['season'] == season]):\n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['hum'].values[i] += hum_std\n",
    "            else:\n",
    "                seasonal_data['hum'].values[i] -= hum_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['wind_speed'].values[i] += wind_speed_std\n",
    "            else:\n",
    "                seasonal_data['wind_speed'].values[i] -= wind_speed_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['t1'].values[i] += t1_std\n",
    "            else:\n",
    "                seasonal_data['t1'].values[i] -= t1_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['t2'].values[i] += t2_std\n",
    "            else:\n",
    "                seasonal_data['t2'].values[i] -= t2_std\n",
    "        \n",
    "    return gen_data\n",
    "\n",
    "gen = data_enhancement(data)\n",
    "\n",
    "#print(gen.shape)\n",
    "\n",
    "#final_data = data\n",
    "y = data['cnt']\n",
    "x = data.drop(['cnt'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#print(data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_vars = ['season','is_weekend','is_holiday','year','month','weather_code']\n",
    "num_vars = ['t1','t2','hum','wind_speed']\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(x, y,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0  # Recommended for reproducibility\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "extra_sample = gen.sample(gen.shape[0] // 2)\n",
    "x_train = pd.concat([x_train, extra_sample.drop(['cnt'], axis=1 ) ])\n",
    "y_train = pd.concat([y_train, extra_sample['cnt'] ])\n",
    "\n",
    "\n",
    "transformer = preprocessing.PowerTransformer()\n",
    "y_train = transformer.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_val = transformer.transform(y_val.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "rang = abs(y_train.max()) + abs(y_train.min())\n",
    "\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value=-9999)),\n",
    "])\n",
    "\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', preprocessing.OrdinalEncoder()) # handle_unknown='ignore' ONLY IN VERSION 0.24\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_4_treeModels, num_vars),\n",
    "    ('cat', cat_4_treeModels, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeRegressor(),\n",
    "  \"Extra Trees\":   ExtraTreesRegressor(n_estimators=100),\n",
    "  \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "  \"AdaBoost\":      AdaBoostRegressor(n_estimators=100),\n",
    "  \"Skl GBM\":       GradientBoostingRegressor(n_estimators=100),\n",
    "  \"XGBoost\":       XGBRegressor(n_estimators=100),\n",
    "  \"LightGBM\":      LGBMRegressor(n_estimators=100),\n",
    "  \"CatBoost\":      CatBoostRegressor(n_estimators=100),\n",
    "}\n",
    "### END SOLUTIONv\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], \" % error\": [], 'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    total_time = time.time() - start_time\n",
    "        \n",
    "    pred = model.predict(x_val)\n",
    "    \n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"MSE\": metrics.mean_squared_error(y_val, pred),\n",
    "                              \"MAB\": metrics.mean_absolute_error(y_val, pred),\n",
    "                              \" % error\": metrics.mean_squared_error(y_val, pred) / rang,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['MSE'], ascending=True, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['MSE', 'MAE'], vmin=0, vmax=100, color='#5fba7d')\n",
    "\n",
    "print(results_ord)\n",
    "\n",
    "\n",
    "print(y_train.max())\n",
    "print(y_train.min())\n",
    "print(y_val[3])\n",
    "print(tree_classifiers['Random Forest'].predict(x_val)[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Learning rate set to 0.391347\n",
      "0:\tlearn: 0.8955776\ttotal: 4.07ms\tremaining: 403ms\n",
      "1:\tlearn: 0.8506618\ttotal: 7.68ms\tremaining: 377ms\n",
      "2:\tlearn: 0.8252210\ttotal: 11.2ms\tremaining: 362ms\n",
      "3:\tlearn: 0.8093339\ttotal: 14.8ms\tremaining: 355ms\n",
      "4:\tlearn: 0.8010627\ttotal: 18.9ms\tremaining: 359ms\n",
      "5:\tlearn: 0.7949905\ttotal: 22.7ms\tremaining: 356ms\n",
      "6:\tlearn: 0.7910546\ttotal: 26.3ms\tremaining: 349ms\n",
      "7:\tlearn: 0.7875367\ttotal: 29.7ms\tremaining: 342ms\n",
      "8:\tlearn: 0.7838384\ttotal: 33.5ms\tremaining: 339ms\n",
      "9:\tlearn: 0.7810520\ttotal: 37.2ms\tremaining: 334ms\n",
      "10:\tlearn: 0.7793134\ttotal: 40.6ms\tremaining: 329ms\n",
      "11:\tlearn: 0.7775242\ttotal: 44ms\tremaining: 323ms\n",
      "12:\tlearn: 0.7753317\ttotal: 47.9ms\tremaining: 320ms\n",
      "13:\tlearn: 0.7736978\ttotal: 51.8ms\tremaining: 318ms\n",
      "14:\tlearn: 0.7721737\ttotal: 55.4ms\tremaining: 314ms\n",
      "15:\tlearn: 0.7710307\ttotal: 58.6ms\tremaining: 308ms\n",
      "16:\tlearn: 0.7694937\ttotal: 62ms\tremaining: 303ms\n",
      "17:\tlearn: 0.7679738\ttotal: 65.6ms\tremaining: 299ms\n",
      "18:\tlearn: 0.7670821\ttotal: 69ms\tremaining: 294ms\n",
      "19:\tlearn: 0.7664732\ttotal: 72.8ms\tremaining: 291ms\n",
      "20:\tlearn: 0.7642829\ttotal: 76.4ms\tremaining: 288ms\n",
      "21:\tlearn: 0.7637888\ttotal: 80.1ms\tremaining: 284ms\n",
      "22:\tlearn: 0.7623782\ttotal: 83.6ms\tremaining: 280ms\n",
      "23:\tlearn: 0.7610787\ttotal: 86.9ms\tremaining: 275ms\n",
      "24:\tlearn: 0.7598562\ttotal: 90.3ms\tremaining: 271ms\n",
      "25:\tlearn: 0.7584261\ttotal: 93.6ms\tremaining: 266ms\n",
      "26:\tlearn: 0.7566581\ttotal: 97.3ms\tremaining: 263ms\n",
      "27:\tlearn: 0.7547417\ttotal: 101ms\tremaining: 259ms\n",
      "28:\tlearn: 0.7542107\ttotal: 104ms\tremaining: 255ms\n",
      "29:\tlearn: 0.7533594\ttotal: 108ms\tremaining: 251ms\n",
      "30:\tlearn: 0.7527960\ttotal: 111ms\tremaining: 247ms\n",
      "31:\tlearn: 0.7513539\ttotal: 115ms\tremaining: 245ms\n",
      "32:\tlearn: 0.7499516\ttotal: 119ms\tremaining: 241ms\n",
      "33:\tlearn: 0.7485129\ttotal: 122ms\tremaining: 237ms\n",
      "34:\tlearn: 0.7478298\ttotal: 126ms\tremaining: 233ms\n",
      "35:\tlearn: 0.7476569\ttotal: 129ms\tremaining: 229ms\n",
      "36:\tlearn: 0.7474440\ttotal: 132ms\tremaining: 225ms\n",
      "37:\tlearn: 0.7458749\ttotal: 135ms\tremaining: 221ms\n",
      "38:\tlearn: 0.7443952\ttotal: 139ms\tremaining: 218ms\n",
      "39:\tlearn: 0.7430444\ttotal: 143ms\tremaining: 215ms\n",
      "40:\tlearn: 0.7422763\ttotal: 147ms\tremaining: 212ms\n",
      "41:\tlearn: 0.7410204\ttotal: 151ms\tremaining: 208ms\n",
      "42:\tlearn: 0.7404413\ttotal: 154ms\tremaining: 205ms\n",
      "43:\tlearn: 0.7390553\ttotal: 158ms\tremaining: 201ms\n",
      "44:\tlearn: 0.7382573\ttotal: 162ms\tremaining: 198ms\n",
      "45:\tlearn: 0.7375768\ttotal: 166ms\tremaining: 195ms\n",
      "46:\tlearn: 0.7368674\ttotal: 170ms\tremaining: 192ms\n",
      "47:\tlearn: 0.7355335\ttotal: 175ms\tremaining: 189ms\n",
      "48:\tlearn: 0.7344964\ttotal: 178ms\tremaining: 186ms\n",
      "49:\tlearn: 0.7343958\ttotal: 182ms\tremaining: 182ms\n",
      "50:\tlearn: 0.7340904\ttotal: 185ms\tremaining: 178ms\n",
      "51:\tlearn: 0.7327616\ttotal: 189ms\tremaining: 174ms\n",
      "52:\tlearn: 0.7322302\ttotal: 192ms\tremaining: 171ms\n",
      "53:\tlearn: 0.7313479\ttotal: 197ms\tremaining: 168ms\n",
      "54:\tlearn: 0.7307803\ttotal: 201ms\tremaining: 164ms\n",
      "55:\tlearn: 0.7305298\ttotal: 204ms\tremaining: 160ms\n",
      "56:\tlearn: 0.7296174\ttotal: 207ms\tremaining: 157ms\n",
      "57:\tlearn: 0.7292678\ttotal: 211ms\tremaining: 153ms\n",
      "58:\tlearn: 0.7278527\ttotal: 214ms\tremaining: 149ms\n",
      "59:\tlearn: 0.7273253\ttotal: 217ms\tremaining: 145ms\n",
      "60:\tlearn: 0.7263120\ttotal: 221ms\tremaining: 141ms\n",
      "61:\tlearn: 0.7259593\ttotal: 224ms\tremaining: 138ms\n",
      "62:\tlearn: 0.7249165\ttotal: 228ms\tremaining: 134ms\n",
      "63:\tlearn: 0.7237054\ttotal: 232ms\tremaining: 130ms\n",
      "64:\tlearn: 0.7230032\ttotal: 235ms\tremaining: 126ms\n",
      "65:\tlearn: 0.7213718\ttotal: 239ms\tremaining: 123ms\n",
      "66:\tlearn: 0.7212902\ttotal: 242ms\tremaining: 119ms\n",
      "67:\tlearn: 0.7212782\ttotal: 245ms\tremaining: 115ms\n",
      "68:\tlearn: 0.7208812\ttotal: 248ms\tremaining: 111ms\n",
      "69:\tlearn: 0.7196034\ttotal: 252ms\tremaining: 108ms\n",
      "70:\tlearn: 0.7189434\ttotal: 255ms\tremaining: 104ms\n",
      "71:\tlearn: 0.7184659\ttotal: 260ms\tremaining: 101ms\n",
      "72:\tlearn: 0.7170495\ttotal: 263ms\tremaining: 97.4ms\n",
      "73:\tlearn: 0.7163004\ttotal: 267ms\tremaining: 93.7ms\n",
      "74:\tlearn: 0.7153048\ttotal: 270ms\tremaining: 90.1ms\n",
      "75:\tlearn: 0.7142173\ttotal: 274ms\tremaining: 86.4ms\n",
      "76:\tlearn: 0.7134453\ttotal: 277ms\tremaining: 82.8ms\n",
      "77:\tlearn: 0.7124503\ttotal: 281ms\tremaining: 79.1ms\n",
      "78:\tlearn: 0.7114621\ttotal: 284ms\tremaining: 75.5ms\n",
      "79:\tlearn: 0.7107530\ttotal: 288ms\tremaining: 72ms\n",
      "80:\tlearn: 0.7102947\ttotal: 291ms\tremaining: 68.3ms\n",
      "81:\tlearn: 0.7094059\ttotal: 295ms\tremaining: 64.7ms\n",
      "82:\tlearn: 0.7084498\ttotal: 298ms\tremaining: 61ms\n",
      "83:\tlearn: 0.7074424\ttotal: 302ms\tremaining: 57.5ms\n",
      "84:\tlearn: 0.7068819\ttotal: 305ms\tremaining: 53.9ms\n",
      "85:\tlearn: 0.7058308\ttotal: 309ms\tremaining: 50.3ms\n",
      "86:\tlearn: 0.7053433\ttotal: 312ms\tremaining: 46.7ms\n",
      "87:\tlearn: 0.7052719\ttotal: 316ms\tremaining: 43.1ms\n",
      "88:\tlearn: 0.7042742\ttotal: 320ms\tremaining: 39.5ms\n",
      "89:\tlearn: 0.7037506\ttotal: 323ms\tremaining: 35.9ms\n",
      "90:\tlearn: 0.7030337\ttotal: 326ms\tremaining: 32.3ms\n",
      "91:\tlearn: 0.7024603\ttotal: 330ms\tremaining: 28.7ms\n",
      "92:\tlearn: 0.7019300\ttotal: 333ms\tremaining: 25.1ms\n",
      "93:\tlearn: 0.7017070\ttotal: 337ms\tremaining: 21.5ms\n",
      "94:\tlearn: 0.7016082\ttotal: 340ms\tremaining: 17.9ms\n",
      "95:\tlearn: 0.7012378\ttotal: 343ms\tremaining: 14.3ms\n",
      "96:\tlearn: 0.7005569\ttotal: 347ms\tremaining: 10.7ms\n",
      "97:\tlearn: 0.6999692\ttotal: 352ms\tremaining: 7.18ms\n",
      "98:\tlearn: 0.6993246\ttotal: 356ms\tremaining: 3.59ms\n",
      "99:\tlearn: 0.6986483\ttotal: 359ms\tremaining: 0us\n",
      "           Model       MSE       MAB   % error      Time\n",
      "1    Extra Trees  0.100231  0.098581  0.018193  4.076110\n",
      "2  Random Forest  0.157411  0.259451  0.028572  5.345715\n",
      "3  Decision Tree  0.168089  0.125617  0.030511  0.148609\n",
      "4        XGBoost  0.438427  0.500075  0.079581  0.682155\n",
      "5       LightGBM  0.526806  0.558607  0.095623  0.257311\n",
      "6       CatBoost  0.533220  0.558990  0.096787  0.578882\n",
      "7        Skl GBM  0.610098  0.606010  0.110742  1.517965\n",
      "8       AdaBoost  0.690006  0.660741  0.125246  0.312166\n",
      "2.7549301833546767\n",
      "-2.7542779504178214\n",
      "[0.56333969]\n",
      "1.2636186431042136\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}