{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('dl': conda)"
  },
  "interpreter": {
   "hash": "6afb89b99e84bee04d6330a29f1bb71213540d48d5fe88c31e05e7f9706c13f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style='seaborn')\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model #for lasso\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import model_selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/london_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                timestamp   cnt    t1    t2   hum  wind_speed  weather_code  \\\n",
       "5631  2015-08-27 06:00:00   685  15.0  15.0  82.0        14.0           2.0   \n",
       "6134  2015-09-17 13:00:00  1402  17.0  17.0  54.0        22.0           2.0   \n",
       "4007  2015-06-20 10:00:00  1571  17.0  17.0  64.0         7.0           3.0   \n",
       "5750  2015-09-01 05:00:00   116  15.0  15.0  85.0        11.0           3.0   \n",
       "1644  2015-03-13 14:00:00  1164  11.0  11.0  44.0        26.0           1.0   \n",
       "\n",
       "      is_holiday  is_weekend  season  \n",
       "5631         0.0         0.0     1.0  \n",
       "6134         0.0         0.0     2.0  \n",
       "4007         0.0         1.0     1.0  \n",
       "5750         0.0         0.0     2.0  \n",
       "1644         0.0         0.0     0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>cnt</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>hum</th>\n      <th>wind_speed</th>\n      <th>weather_code</th>\n      <th>is_holiday</th>\n      <th>is_weekend</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5631</th>\n      <td>2015-08-27 06:00:00</td>\n      <td>685</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>82.0</td>\n      <td>14.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6134</th>\n      <td>2015-09-17 13:00:00</td>\n      <td>1402</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>54.0</td>\n      <td>22.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4007</th>\n      <td>2015-06-20 10:00:00</td>\n      <td>1571</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>64.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5750</th>\n      <td>2015-09-01 05:00:00</td>\n      <td>116</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>85.0</td>\n      <td>11.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>2015-03-13 14:00:00</td>\n      <td>1164</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>44.0</td>\n      <td>26.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cnt    t1    t2   hum  wind_speed  weather_code  is_holiday  \\\n",
       "6577     70  16.0  16.0  94.0        12.0           7.0         0.0   \n",
       "284     591   6.5   1.5  57.0        32.0           1.0         0.0   \n",
       "6996   1535  13.5  13.5  65.0        10.0           4.0         0.0   \n",
       "14382   476  18.5  18.5  83.0        10.0           3.0         1.0   \n",
       "3311   1970  11.0  11.0  77.0        13.0           1.0         0.0   \n",
       "10035   230   4.0   0.0  75.0        18.0           4.0         0.0   \n",
       "16194    46   7.5   5.5  87.0         9.0           2.0         0.0   \n",
       "12241   585  15.0  15.0  68.0        23.5           1.0         1.0   \n",
       "6951    592  15.0  15.0  88.0        14.0           4.0         0.0   \n",
       "2335   2713  13.5  13.5  37.0        26.0           1.0         0.0   \n",
       "\n",
       "       is_weekend  season  year month hour  \n",
       "6577          0.0     2.0  2015    10   01  \n",
       "284           0.0     3.0  2015    01   21  \n",
       "6996          0.0     2.0  2015    10   19  \n",
       "14382         0.0     1.0  2016    08   01  \n",
       "3311          0.0     0.0  2015    05   07  \n",
       "10035         1.0     3.0  2016    02   08  \n",
       "16194         0.0     2.0  2016    11   04  \n",
       "12241         0.0     0.0  2016    05   22  \n",
       "6951          0.0     2.0  2015    10   22  \n",
       "2335          1.0     0.0  2015    04   15  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cnt</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>hum</th>\n      <th>wind_speed</th>\n      <th>weather_code</th>\n      <th>is_holiday</th>\n      <th>is_weekend</th>\n      <th>season</th>\n      <th>year</th>\n      <th>month</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6577</th>\n      <td>70</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>94.0</td>\n      <td>12.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2015</td>\n      <td>10</td>\n      <td>01</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>591</td>\n      <td>6.5</td>\n      <td>1.5</td>\n      <td>57.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>6996</th>\n      <td>1535</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>65.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2015</td>\n      <td>10</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>14382</th>\n      <td>476</td>\n      <td>18.5</td>\n      <td>18.5</td>\n      <td>83.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2016</td>\n      <td>08</td>\n      <td>01</td>\n    </tr>\n    <tr>\n      <th>3311</th>\n      <td>1970</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>77.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>05</td>\n      <td>07</td>\n    </tr>\n    <tr>\n      <th>10035</th>\n      <td>230</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>18.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2016</td>\n      <td>02</td>\n      <td>08</td>\n    </tr>\n    <tr>\n      <th>16194</th>\n      <td>46</td>\n      <td>7.5</td>\n      <td>5.5</td>\n      <td>87.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2016</td>\n      <td>11</td>\n      <td>04</td>\n    </tr>\n    <tr>\n      <th>12241</th>\n      <td>585</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>68.0</td>\n      <td>23.5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2016</td>\n      <td>05</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6951</th>\n      <td>592</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>88.0</td>\n      <td>14.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2015</td>\n      <td>10</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2335</th>\n      <td>2713</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>37.0</td>\n      <td>26.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>04</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "#adding 25% features to wind speed\n",
    "#new_df['wind_speed'] = new_df.apply(lambda row: row['wind_speed'] + np.random.random_sample()*1000, axis=1 )\n",
    "#adding 25% features to temp \n",
    "#new_df['t2']  = new_df.apply(lambda row: row['t2'] + np.random.random_sample()*2, axis=1)\n",
    "\n",
    "df = df.append(new_df.sample(int(new_df.shape[0]/4)))\n",
    "\n",
    "#enhancing data\n",
    "df['year'] = df['timestamp'].apply(lambda row: row[:4])\n",
    "df['month'] = df['timestamp'].apply(lambda row: row[5:7])\n",
    "df['hour'] = df['timestamp'].apply(lambda row: row[11:13])\n",
    "\n",
    "df = df.drop(['timestamp'], axis =1)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3., 0., 1., 2.])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data\n",
    "def data_enhancement(data):\n",
    "    \n",
    "    gen_data = df.copy()\n",
    "    for season in data['season'].unique():\n",
    "        seasonal_data = gen_data[ gen_data['season'] == season]\n",
    "        \n",
    "        t1_std   = seasonal_data['t1'].std()\n",
    "        t2_std   = seasonal_data['t2'].std()\n",
    "        hum_std  = seasonal_data['hum'].std()\n",
    "        wind_std = seasonal_data['wind_speed'].std()\n",
    "\n",
    "        for i in range(seasonal_data.shape[0]):\n",
    "            if np.random.randint(2) == 1: #losuje liczbe od 0 do 1  \n",
    "                seasonal_data['t1'].values[i] += t1_std\n",
    "            else:\n",
    "                seasonal_data['t1'].values[i] -= t1_std   \n",
    "\n",
    "            if np.random.randint(2) == 1:  \n",
    "                seasonal_data['t2'].values[i] += t2_std\n",
    "            else:\n",
    "                seasonal_data['t2'].values[i] -= t2_std   \n",
    "        \n",
    "            if np.random.randint(2) == 1:   \n",
    "                seasonal_data['hum'].values[i] += hum_std\n",
    "            else:\n",
    "                seasonal_data['hum'].values[i] -= hum_std\n",
    "\n",
    "            if np.random.randint(2) == 1:  \n",
    "                seasonal_data['wind_speed'].values[i] += wind_std\n",
    "            else:\n",
    "                seasonal_data['wind_speed'].values[i] -= wind_std\n",
    "        \n",
    "    return gen_data\n",
    "\n",
    "gen = data_enhancement(df)                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cnt    t1         t2    hum  wind_speed  weather_code  is_holiday  \\\n",
       "0       182   3.0   2.000000   93.0    6.000000           3.0         0.0   \n",
       "1       138   3.0   2.500000   93.0    5.000000           1.0         0.0   \n",
       "2       134   2.5   2.500000   96.5    0.000000           1.0         0.0   \n",
       "3        72   2.0   2.000000  100.0    0.000000           1.0         0.0   \n",
       "4        47   2.0   0.000000   93.0    6.500000           1.0         0.0   \n",
       "...     ...   ...        ...    ...         ...           ...         ...   \n",
       "238     340   5.0   1.135830   70.0  952.981578           1.0         0.0   \n",
       "936      63   4.0   4.318563   75.0  306.405440           4.0         0.0   \n",
       "17186  3665  14.0  14.987899   77.0  125.733813           3.0         0.0   \n",
       "6020   1539  17.5  17.594161   57.5  147.351105           2.0         0.0   \n",
       "4878    521  17.5  18.639612   80.5  265.506764           2.0         0.0   \n",
       "\n",
       "       is_weekend  season  year month hour  \n",
       "0             1.0     3.0  2015    01   00  \n",
       "1             1.0     3.0  2015    01   01  \n",
       "2             1.0     3.0  2015    01   02  \n",
       "3             1.0     3.0  2015    01   03  \n",
       "4             1.0     3.0  2015    01   04  \n",
       "...           ...     ...   ...   ...  ...  \n",
       "238           0.0     3.0  2015    01   23  \n",
       "936           0.0     3.0  2015    02   02  \n",
       "17186         1.0     3.0  2016    12   12  \n",
       "6020          1.0     2.0  2015    09   19  \n",
       "4878          1.0     1.0  2015    07   21  \n",
       "\n",
       "[21767 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cnt</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>hum</th>\n      <th>wind_speed</th>\n      <th>weather_code</th>\n      <th>is_holiday</th>\n      <th>is_weekend</th>\n      <th>season</th>\n      <th>year</th>\n      <th>month</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>182</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>93.0</td>\n      <td>6.000000</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>138</td>\n      <td>3.0</td>\n      <td>2.500000</td>\n      <td>93.0</td>\n      <td>5.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134</td>\n      <td>2.5</td>\n      <td>2.500000</td>\n      <td>96.5</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>2.0</td>\n      <td>2.000000</td>\n      <td>100.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>93.0</td>\n      <td>6.500000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>04</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>340</td>\n      <td>5.0</td>\n      <td>1.135830</td>\n      <td>70.0</td>\n      <td>952.981578</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>01</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>63</td>\n      <td>4.0</td>\n      <td>4.318563</td>\n      <td>75.0</td>\n      <td>306.405440</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2015</td>\n      <td>02</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>17186</th>\n      <td>3665</td>\n      <td>14.0</td>\n      <td>14.987899</td>\n      <td>77.0</td>\n      <td>125.733813</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2016</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>6020</th>\n      <td>1539</td>\n      <td>17.5</td>\n      <td>17.594161</td>\n      <td>57.5</td>\n      <td>147.351105</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2015</td>\n      <td>09</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4878</th>\n      <td>521</td>\n      <td>17.5</td>\n      <td>18.639612</td>\n      <td>80.5</td>\n      <td>265.506764</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015</td>\n      <td>07</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>21767 rows × 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t1', 't2', 'hum', 'wind_speed']"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "cat_vars = ['weather_code', 'is_holiday','is_weekend','season','year','month']\n",
    "num_vars = ['t1','t2','hum','wind_speed']\n",
    "num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cnt']\n",
    "x = df.drop(['cnt'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val , y_train, y_val = model_selection.train_test_split(x,y ,test_size = 0.2 , random_state = 0)\n",
    "\n",
    "#generating extar samples \n",
    "\n",
    "extra_sample = gen.sample(gen.shape[0] // 3 ) # generating 30% new data\n",
    "\n",
    "#concatinating extra sample to training data\n",
    "x_train = pd.concat([x_train, extra_sample.drop(['cnt'], axis=1)])\n",
    "y_train = pd.concat([y_train, extra_sample['cnt']])\n",
    "\n",
    "#normalazing data labels\n",
    "transformer = preprocessing.PowerTransformer()\n",
    "y_train = transformer.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_val = transformer.transform(y_val.values.reshape(-1,1))\n",
    "\n",
    "rang = abs(y_train.max()) + abs(y_train.min())\n",
    "\n",
    "#applying imputer to fill missing num & cat data\n",
    "\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value=-9999)),\n",
    "])\n",
    "\n",
    "\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', preprocessing.OrdinalEncoder())\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_4_treeModels, num_vars),\n",
    "    ('cat', cat_4_treeModels, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "\n",
    "#dictionary of all algorithms that I am going to test \n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Extra Trees\":ExtraTreesClassifier(),\n",
    "  \"Random Forest\":RandomForestClassifier(),\n",
    "  \"AdaBoost\":AdaBoostClassifier(),\n",
    "  \"Skl GBM\":GradientBoostingClassifier(),\n",
    "  \"Skl HistGBM\":GradientBoostingClassifier(),\n",
    "  \"XGBoost\":XGBClassifier(),\n",
    "  \"LightGBM\":LGBMClassifier(),\n",
    "  \"CatBoost\":CatBoostClassifier()\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-f22a2bc769e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \"\"\"\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "#putting everything together\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepo, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], \" % error\": [], 'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    total_time = time.time() - start_time\n",
    "        \n",
    "    pred = model.predict(x_val)\n",
    "    \n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"MSE\": metrics.mean_squared_error(y_val, pred),\n",
    "                              \"MAB\": metrics.mean_absolute_error(y_val, pred),\n",
    "                              \" % error\": metrics.mean_squared_error(y_val, pred) / rang,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['MSE'], ascending=True, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['MSE', 'MAE'], vmin=0, vmax=100, color='#5fba7d')\n",
    "\n",
    "print(results_ord)\n",
    "\n",
    "\n",
    "print(y_train.max())\n",
    "print(y_train.min())\n",
    "print(y_val[3])\n",
    "print(tree_classifiers['Random Forest'].predict(x_val)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Wojtek\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Learning rate set to 0.391347\n",
      "0:\tlearn: 0.8955776\ttotal: 4.07ms\tremaining: 403ms\n",
      "1:\tlearn: 0.8506618\ttotal: 7.68ms\tremaining: 377ms\n",
      "2:\tlearn: 0.8252210\ttotal: 11.2ms\tremaining: 362ms\n",
      "3:\tlearn: 0.8093339\ttotal: 14.8ms\tremaining: 355ms\n",
      "4:\tlearn: 0.8010627\ttotal: 18.9ms\tremaining: 359ms\n",
      "5:\tlearn: 0.7949905\ttotal: 22.7ms\tremaining: 356ms\n",
      "6:\tlearn: 0.7910546\ttotal: 26.3ms\tremaining: 349ms\n",
      "7:\tlearn: 0.7875367\ttotal: 29.7ms\tremaining: 342ms\n",
      "8:\tlearn: 0.7838384\ttotal: 33.5ms\tremaining: 339ms\n",
      "9:\tlearn: 0.7810520\ttotal: 37.2ms\tremaining: 334ms\n",
      "10:\tlearn: 0.7793134\ttotal: 40.6ms\tremaining: 329ms\n",
      "11:\tlearn: 0.7775242\ttotal: 44ms\tremaining: 323ms\n",
      "12:\tlearn: 0.7753317\ttotal: 47.9ms\tremaining: 320ms\n",
      "13:\tlearn: 0.7736978\ttotal: 51.8ms\tremaining: 318ms\n",
      "14:\tlearn: 0.7721737\ttotal: 55.4ms\tremaining: 314ms\n",
      "15:\tlearn: 0.7710307\ttotal: 58.6ms\tremaining: 308ms\n",
      "16:\tlearn: 0.7694937\ttotal: 62ms\tremaining: 303ms\n",
      "17:\tlearn: 0.7679738\ttotal: 65.6ms\tremaining: 299ms\n",
      "18:\tlearn: 0.7670821\ttotal: 69ms\tremaining: 294ms\n",
      "19:\tlearn: 0.7664732\ttotal: 72.8ms\tremaining: 291ms\n",
      "20:\tlearn: 0.7642829\ttotal: 76.4ms\tremaining: 288ms\n",
      "21:\tlearn: 0.7637888\ttotal: 80.1ms\tremaining: 284ms\n",
      "22:\tlearn: 0.7623782\ttotal: 83.6ms\tremaining: 280ms\n",
      "23:\tlearn: 0.7610787\ttotal: 86.9ms\tremaining: 275ms\n",
      "24:\tlearn: 0.7598562\ttotal: 90.3ms\tremaining: 271ms\n",
      "25:\tlearn: 0.7584261\ttotal: 93.6ms\tremaining: 266ms\n",
      "26:\tlearn: 0.7566581\ttotal: 97.3ms\tremaining: 263ms\n",
      "27:\tlearn: 0.7547417\ttotal: 101ms\tremaining: 259ms\n",
      "28:\tlearn: 0.7542107\ttotal: 104ms\tremaining: 255ms\n",
      "29:\tlearn: 0.7533594\ttotal: 108ms\tremaining: 251ms\n",
      "30:\tlearn: 0.7527960\ttotal: 111ms\tremaining: 247ms\n",
      "31:\tlearn: 0.7513539\ttotal: 115ms\tremaining: 245ms\n",
      "32:\tlearn: 0.7499516\ttotal: 119ms\tremaining: 241ms\n",
      "33:\tlearn: 0.7485129\ttotal: 122ms\tremaining: 237ms\n",
      "34:\tlearn: 0.7478298\ttotal: 126ms\tremaining: 233ms\n",
      "35:\tlearn: 0.7476569\ttotal: 129ms\tremaining: 229ms\n",
      "36:\tlearn: 0.7474440\ttotal: 132ms\tremaining: 225ms\n",
      "37:\tlearn: 0.7458749\ttotal: 135ms\tremaining: 221ms\n",
      "38:\tlearn: 0.7443952\ttotal: 139ms\tremaining: 218ms\n",
      "39:\tlearn: 0.7430444\ttotal: 143ms\tremaining: 215ms\n",
      "40:\tlearn: 0.7422763\ttotal: 147ms\tremaining: 212ms\n",
      "41:\tlearn: 0.7410204\ttotal: 151ms\tremaining: 208ms\n",
      "42:\tlearn: 0.7404413\ttotal: 154ms\tremaining: 205ms\n",
      "43:\tlearn: 0.7390553\ttotal: 158ms\tremaining: 201ms\n",
      "44:\tlearn: 0.7382573\ttotal: 162ms\tremaining: 198ms\n",
      "45:\tlearn: 0.7375768\ttotal: 166ms\tremaining: 195ms\n",
      "46:\tlearn: 0.7368674\ttotal: 170ms\tremaining: 192ms\n",
      "47:\tlearn: 0.7355335\ttotal: 175ms\tremaining: 189ms\n",
      "48:\tlearn: 0.7344964\ttotal: 178ms\tremaining: 186ms\n",
      "49:\tlearn: 0.7343958\ttotal: 182ms\tremaining: 182ms\n",
      "50:\tlearn: 0.7340904\ttotal: 185ms\tremaining: 178ms\n",
      "51:\tlearn: 0.7327616\ttotal: 189ms\tremaining: 174ms\n",
      "52:\tlearn: 0.7322302\ttotal: 192ms\tremaining: 171ms\n",
      "53:\tlearn: 0.7313479\ttotal: 197ms\tremaining: 168ms\n",
      "54:\tlearn: 0.7307803\ttotal: 201ms\tremaining: 164ms\n",
      "55:\tlearn: 0.7305298\ttotal: 204ms\tremaining: 160ms\n",
      "56:\tlearn: 0.7296174\ttotal: 207ms\tremaining: 157ms\n",
      "57:\tlearn: 0.7292678\ttotal: 211ms\tremaining: 153ms\n",
      "58:\tlearn: 0.7278527\ttotal: 214ms\tremaining: 149ms\n",
      "59:\tlearn: 0.7273253\ttotal: 217ms\tremaining: 145ms\n",
      "60:\tlearn: 0.7263120\ttotal: 221ms\tremaining: 141ms\n",
      "61:\tlearn: 0.7259593\ttotal: 224ms\tremaining: 138ms\n",
      "62:\tlearn: 0.7249165\ttotal: 228ms\tremaining: 134ms\n",
      "63:\tlearn: 0.7237054\ttotal: 232ms\tremaining: 130ms\n",
      "64:\tlearn: 0.7230032\ttotal: 235ms\tremaining: 126ms\n",
      "65:\tlearn: 0.7213718\ttotal: 239ms\tremaining: 123ms\n",
      "66:\tlearn: 0.7212902\ttotal: 242ms\tremaining: 119ms\n",
      "67:\tlearn: 0.7212782\ttotal: 245ms\tremaining: 115ms\n",
      "68:\tlearn: 0.7208812\ttotal: 248ms\tremaining: 111ms\n",
      "69:\tlearn: 0.7196034\ttotal: 252ms\tremaining: 108ms\n",
      "70:\tlearn: 0.7189434\ttotal: 255ms\tremaining: 104ms\n",
      "71:\tlearn: 0.7184659\ttotal: 260ms\tremaining: 101ms\n",
      "72:\tlearn: 0.7170495\ttotal: 263ms\tremaining: 97.4ms\n",
      "73:\tlearn: 0.7163004\ttotal: 267ms\tremaining: 93.7ms\n",
      "74:\tlearn: 0.7153048\ttotal: 270ms\tremaining: 90.1ms\n",
      "75:\tlearn: 0.7142173\ttotal: 274ms\tremaining: 86.4ms\n",
      "76:\tlearn: 0.7134453\ttotal: 277ms\tremaining: 82.8ms\n",
      "77:\tlearn: 0.7124503\ttotal: 281ms\tremaining: 79.1ms\n",
      "78:\tlearn: 0.7114621\ttotal: 284ms\tremaining: 75.5ms\n",
      "79:\tlearn: 0.7107530\ttotal: 288ms\tremaining: 72ms\n",
      "80:\tlearn: 0.7102947\ttotal: 291ms\tremaining: 68.3ms\n",
      "81:\tlearn: 0.7094059\ttotal: 295ms\tremaining: 64.7ms\n",
      "82:\tlearn: 0.7084498\ttotal: 298ms\tremaining: 61ms\n",
      "83:\tlearn: 0.7074424\ttotal: 302ms\tremaining: 57.5ms\n",
      "84:\tlearn: 0.7068819\ttotal: 305ms\tremaining: 53.9ms\n",
      "85:\tlearn: 0.7058308\ttotal: 309ms\tremaining: 50.3ms\n",
      "86:\tlearn: 0.7053433\ttotal: 312ms\tremaining: 46.7ms\n",
      "87:\tlearn: 0.7052719\ttotal: 316ms\tremaining: 43.1ms\n",
      "88:\tlearn: 0.7042742\ttotal: 320ms\tremaining: 39.5ms\n",
      "89:\tlearn: 0.7037506\ttotal: 323ms\tremaining: 35.9ms\n",
      "90:\tlearn: 0.7030337\ttotal: 326ms\tremaining: 32.3ms\n",
      "91:\tlearn: 0.7024603\ttotal: 330ms\tremaining: 28.7ms\n",
      "92:\tlearn: 0.7019300\ttotal: 333ms\tremaining: 25.1ms\n",
      "93:\tlearn: 0.7017070\ttotal: 337ms\tremaining: 21.5ms\n",
      "94:\tlearn: 0.7016082\ttotal: 340ms\tremaining: 17.9ms\n",
      "95:\tlearn: 0.7012378\ttotal: 343ms\tremaining: 14.3ms\n",
      "96:\tlearn: 0.7005569\ttotal: 347ms\tremaining: 10.7ms\n",
      "97:\tlearn: 0.6999692\ttotal: 352ms\tremaining: 7.18ms\n",
      "98:\tlearn: 0.6993246\ttotal: 356ms\tremaining: 3.59ms\n",
      "99:\tlearn: 0.6986483\ttotal: 359ms\tremaining: 0us\n",
      "           Model       MSE       MAB   % error      Time\n",
      "1    Extra Trees  0.100231  0.098581  0.018193  4.076110\n",
      "2  Random Forest  0.157411  0.259451  0.028572  5.345715\n",
      "3  Decision Tree  0.168089  0.125617  0.030511  0.148609\n",
      "4        XGBoost  0.438427  0.500075  0.079581  0.682155\n",
      "5       LightGBM  0.526806  0.558607  0.095623  0.257311\n",
      "6       CatBoost  0.533220  0.558990  0.096787  0.578882\n",
      "7        Skl GBM  0.610098  0.606010  0.110742  1.517965\n",
      "8       AdaBoost  0.690006  0.660741  0.125246  0.312166\n",
      "2.7549301833546767\n",
      "-2.7542779504178214\n",
      "[0.56333969]\n",
      "1.2636186431042136\n"
     ]
    }
   ],
   "source": [
    "\"\"\" ALL IN ONE CELL\"\"\"\n",
    "\n",
    "import numpy    as np\n",
    "from numpy.testing._private.utils import decorate_methods\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "import time\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.tree          import DecisionTreeRegressor\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.ensemble      import ExtraTreesRegressor\n",
    "from sklearn.ensemble      import AdaBoostRegressor\n",
    "from sklearn.ensemble      import GradientBoostingRegressor\n",
    "from xgboost               import XGBRegressor\n",
    "from lightgbm              import LGBMRegressor\n",
    "from catboost              import CatBoostRegressor\n",
    "\n",
    "data = pd.read_csv(r'Data/london_merged.csv')\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#target = data['cnt']\n",
    "#data = data.drop(['cnt'], axis=1)\n",
    "\n",
    "#Print data shape\n",
    "#print(target.shape)\n",
    "#print(data.shape)\n",
    "\n",
    "#Take a look at nulls 0 nulls\n",
    "#print(target.isnull().sum())\n",
    "#print(data.isnull().sum())\n",
    "\n",
    "#lets create a 2 new feautures\n",
    "# Hour time stamp contains the year and the month,\n",
    "# we will create different columns for each one\n",
    "\n",
    "data['year'] = data['timestamp'].apply(lambda row: row[:4])\n",
    "data['month'] = data['timestamp'].apply(lambda row: row.split('-')[2][:2] )\n",
    "data['hour'] = data['timestamp'].apply(lambda row: row.split(':')[0][-2:] )\n",
    "'''\n",
    "print(data['year'])\n",
    "print(data['month'])\n",
    "print(data['hour'])\n",
    "'''\n",
    "data.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "#print(data.shape)\n",
    "\n",
    "\n",
    "def data_enhancement(data):\n",
    "    \n",
    "    gen_data = data.copy()\n",
    "    \n",
    "    for season in data['season'].unique():\n",
    "        seasonal_data =  gen_data[gen_data['season'] == season]\n",
    "        hum_std = seasonal_data['hum'].std()\n",
    "        wind_speed_std = seasonal_data['wind_speed'].std()\n",
    "        t1_std = seasonal_data['t1'].std()\n",
    "        t2_std = seasonal_data['t2'].std()\n",
    "        \n",
    "        for i, d in enumerate(data[data['season'] == season]):\n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['hum'].values[i] += hum_std\n",
    "            else:\n",
    "                seasonal_data['hum'].values[i] -= hum_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['wind_speed'].values[i] += wind_speed_std\n",
    "            else:\n",
    "                seasonal_data['wind_speed'].values[i] -= wind_speed_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['t1'].values[i] += t1_std\n",
    "            else:\n",
    "                seasonal_data['t1'].values[i] -= t1_std\n",
    "                \n",
    "            if np.random.randint(2) == 1:\n",
    "                seasonal_data['t2'].values[i] += t2_std\n",
    "            else:\n",
    "                seasonal_data['t2'].values[i] -= t2_std\n",
    "        \n",
    "    return gen_data\n",
    "\n",
    "gen = data_enhancement(data)\n",
    "\n",
    "#print(gen.shape)\n",
    "\n",
    "#final_data = data\n",
    "y = data['cnt']\n",
    "x = data.drop(['cnt'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#print(data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_vars = ['season','is_weekend','is_holiday','year','month','weather_code']\n",
    "num_vars = ['t1','t2','hum','wind_speed']\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(x, y,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0  # Recommended for reproducibility\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "extra_sample = gen.sample(gen.shape[0] // 2)\n",
    "x_train = pd.concat([x_train, extra_sample.drop(['cnt'], axis=1 ) ])\n",
    "y_train = pd.concat([y_train, extra_sample['cnt'] ])\n",
    "\n",
    "\n",
    "transformer = preprocessing.PowerTransformer()\n",
    "y_train = transformer.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_val = transformer.transform(y_val.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "rang = abs(y_train.max()) + abs(y_train.min())\n",
    "\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value=-9999)),\n",
    "])\n",
    "\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', preprocessing.OrdinalEncoder()) # handle_unknown='ignore' ONLY IN VERSION 0.24\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_4_treeModels, num_vars),\n",
    "    ('cat', cat_4_treeModels, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeRegressor(),\n",
    "  \"Extra Trees\":   ExtraTreesRegressor(n_estimators=100),\n",
    "  \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "  \"AdaBoost\":      AdaBoostRegressor(n_estimators=100),\n",
    "  \"Skl GBM\":       GradientBoostingRegressor(n_estimators=100),\n",
    "  \"XGBoost\":       XGBRegressor(n_estimators=100),\n",
    "  \"LightGBM\":      LGBMRegressor(n_estimators=100),\n",
    "  \"CatBoost\":      CatBoostRegressor(n_estimators=100),\n",
    "}\n",
    "### END SOLUTIONv\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], \" % error\": [], 'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    total_time = time.time() - start_time\n",
    "        \n",
    "    pred = model.predict(x_val)\n",
    "    \n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"MSE\": metrics.mean_squared_error(y_val, pred),\n",
    "                              \"MAB\": metrics.mean_absolute_error(y_val, pred),\n",
    "                              \" % error\": metrics.mean_squared_error(y_val, pred) / rang,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['MSE'], ascending=True, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['MSE', 'MAE'], vmin=0, vmax=100, color='#5fba7d')\n",
    "\n",
    "print(results_ord)\n",
    "\n",
    "\n",
    "print(y_train.max())\n",
    "print(y_train.min())\n",
    "print(y_val[3])\n",
    "print(tree_classifiers['Random Forest'].predict(x_val)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}